<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Local Image Transformations">
    <meta name="author" content="A. Giuliano Mirabella">
    <title>Local Image Transformations</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Local Image Transformations</h1>
        <p>Understanding pixel neighborhood operations in image processing</p>
    </header>

    <div class="container">
        <!-- 1. WHAT IS LOCAL IMAGE PROCESSING? -->
        <h2>What is Local Image Processing?</h2>
        <p>
            <strong>Local image processing</strong> refers to operations that modify the values of pixels in an image based on information 
            from a small, localized neighborhood or region around each pixel. Unlike <em>global transformations</em>—which apply uniform 
            adjustments across the entire image—local transformations adapt their outputs on a pixel-by-pixel basis, 
            typically guided by the context or features in the pixel’s vicinity.
        </p>
        <p>
            This fine-grained control allows for targeted enhancements, such as noise reduction, edge sharpening, and detailed texture analysis. 
            It is particularly important in scenarios where different parts of the image require different processing strategies, 
            such as in medical imaging (highlighting tumor boundaries), surveillance (motion detection in specific regions), 
            and industrial quality control (detecting defects on assembly lines).
        </p>

        <!-- 2. TYPES OF LOCAL IMAGE PROCESSING TECHNIQUES -->
        <h2>Types of Local Image Processing Techniques</h2>
        <p>
            Common local operations rely on a <strong>moving window</strong> or <strong>kernel</strong> that scans over the image. 
            Within this window, pixels are combined according to a specific rule or formula, and the result is written back to the center pixel location. 
            Below are some core categories:
        </p>
        <ul>
            <li><strong>Filtering:</strong> Enhancing or suppressing specific features, such as edges or noise.</li>
            <li><strong>Edge Detection:</strong> Identifying boundaries between distinct regions in an image.</li>
            <li><strong>Morphological Operations:</strong> Processing binary and grayscale images based on their shape; 
                these techniques are widely used for noise removal, gap filling, and shape analysis.</li>
            <li><strong>Texture Analysis:</strong> Extracting local patterns that help in classification, segmentation, or feature extraction.</li>
        </ul>

        <!-- 3. IMAGE FILTERING -->
        <h2>Image Filtering</h2>
        <p>
            <strong>Filtering</strong> in local image processing involves using a kernel (also known as a filter mask or convolution mask) 
            that is applied to each pixel neighborhood. The kernel dimensions (e.g., 3×3, 5×5) and coefficients determine the effect of the filter. 
            Filtering can be linear (convolution-based) or nonlinear (e.g., median filtering).
        </p>
        <ul>
            <li>
                <strong>Smoothing (Blurring):</strong><br>
                These filters reduce random noise and small-scale details in the image. 
                A <em>Gaussian filter</em> uses a weighted, bell-shaped kernel to give more weight to pixels near the center; 
                a <em>median filter</em> replaces each pixel with the median value of its neighborhood, preserving edges better than simple averaging.
            </li>
            <li>
                <strong>Sharpening (High-Pass Filters):</strong><br>
                Instead of smoothing, sharpening filters emphasize edges and fine details. 
                One basic approach is <em>unsharp masking</em>, which subtracts a blurred version of the image from the original to highlight high-frequency content.
            </li>
            <li>
                <strong>Edge Detection:</strong><br>
                While technically a distinct operation, many edge detectors (Sobel, Prewitt, Laplacian) can be seen as specialized filters 
                that respond strongly to intensity changes in specific orientations.
            </li>
        </ul>

        <!-- Code Tabs: Filtering in Python and MATLAB -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-filtering')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-filtering')">MATLAB</div>
        </div>

        <div id="python-filtering" class="code-block active">
            <pre>
import cv2
import numpy as np

# Load an image in grayscale
image = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)

# Apply Gaussian blur
blurred = cv2.GaussianBlur(image, (5,5), 0)
cv2.imwrite('blurred.jpg', blurred)

# Apply median blur
median_blurred = cv2.medianBlur(image, 5)
cv2.imwrite('median_blurred.jpg', median_blurred)
            </pre>
        </div>

        <div id="matlab-filtering" class="code-block">
            <pre>
% Read the grayscale image
image = imread('image.jpg');
image_gray = rgb2gray(image);

% Apply Gaussian blur
kernel_size = [5 5];
sigma = 0; % Standard deviation, 0 lets MATLAB choose
blurred = imgaussfilt(image_gray, sigma, 'FilterSize', kernel_size);
imwrite(blurred, 'blurred.jpg');

% Apply median filter
median_blurred = medfilt2(image_gray, [5 5]);
imwrite(median_blurred, 'median_blurred.jpg');
            </pre>
        </div>

        <!-- 4. EDGE DETECTION -->
        <h2>Edge Detection</h2>
        <p>
            <strong>Edge detection</strong> identifies significant intensity transitions, typically corresponding to object boundaries 
            or abrupt changes in texture. Accurately detecting edges is foundational for segmentation, feature extraction, and object recognition. 
            Two popular approaches:
        </p>
        <ul>
            <li>
                <strong>Sobel/Prewitt Operators:</strong><br>
                These operators approximate the gradient in the horizontal and vertical directions, 
                combining them to produce an edge map. Sobel uses a larger kernel (3×3) and places more weight on the center pixels, 
                whereas Prewitt uses a simpler kernel.
            </li>
            <li>
                <strong>Canny Edge Detector:</strong><br>
                A multi-stage algorithm including noise reduction (via Gaussian blur), gradient calculation, non-maximum suppression, 
                double thresholding, and edge tracking by hysteresis. Canny is often considered the “gold standard” for edge detection 
                because it reduces false positives while preserving accurate boundaries.
            </li>
        </ul>

        <!-- Code Tabs: Canny Edge Detection in Python and MATLAB -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-canny')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-canny')">MATLAB</div>
        </div>

        <div id="python-canny" class="code-block active">
            <pre>
# Canny Edge Detection
edges = cv2.Canny(image, 50, 150)
cv2.imwrite('edges.jpg', edges)
            </pre>
        </div>

        <div id="matlab-canny" class="code-block">
            <pre>
% Read the image
image = imread('input_image.jpg');

% Convert to grayscale if necessary
if size(image, 3) == 3
    image = rgb2gray(image);
end

% Apply Canny edge detection
edges = edge(image, 'Canny', [0.2 0.6]);

% Save the edge-detected image
imwrite(edges, 'edges.jpg');
            </pre>
        </div>

        <!-- 5. MORPHOLOGICAL OPERATIONS -->
        <h2>Morphological Operations</h2>
        <p>
            <strong>Morphological operations</strong> analyze and process images based on <em>shape</em>. 
            They originated from mathematical morphology and are especially useful for binary images, though they can be extended to grayscale. 
            The key idea is to probe or interact with an image using a <em>structuring element</em> that defines the neighborhood shape.
        </p>
        <ul>
            <li>
                <strong>Erosion:</strong><br>
                Removes pixels on object boundaries if the structuring element cannot fully fit inside the object. 
                Used to eliminate small, unwanted regions or to separate objects that are touching.
            </li>
            <li>
                <strong>Dilation:</strong><br>
                Adds pixels to object boundaries, effectively enlarging the object. 
                Commonly used to fill gaps or holes.
            </li>
            <li>
                <strong>Opening:</strong><br>
                An erosion followed by a dilation. Opening removes small objects or noise 
                while mostly preserving the size and shape of larger objects.
            </li>
            <li>
                <strong>Closing:</strong><br>
                A dilation followed by an erosion, used to fill small holes or gaps within objects 
                without significantly altering their overall shape.
            </li>
        </ul>

        <!-- Code Tabs: Morphological Operations in Python and MATLAB -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-morph')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-morph')">MATLAB</div>
        </div>

        <div id="python-morph" class="code-block active">
            <pre>
import cv2
import numpy as np

image = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)

# Create a 5x5 kernel of ones
kernel = np.ones((5,5), np.uint8)

# Erosion
eroded = cv2.erode(image, kernel, iterations=1)
cv2.imwrite('eroded.jpg', eroded)

# Dilation
dilated = cv2.dilate(image, kernel, iterations=1)
cv2.imwrite('dilated.jpg', dilated)

# Opening
opened = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
cv2.imwrite('opened.jpg', opened)

# Closing
closed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
cv2.imwrite('closed.jpg', closed)
            </pre>
        </div>

        <div id="matlab-morph" class="code-block">
            <pre>
image = imread('image.jpg');
if size(image,3) == 3
    image = rgb2gray(image);
end

% Create a 5x5 structuring element
se = strel('square', 5);

% Erosion
eroded = imerode(image, se);
imwrite(eroded, 'eroded.jpg');

% Dilation
dilated = imdilate(image, se);
imwrite(dilated, 'dilated.jpg');

% Opening
opened = imopen(image, se);
imwrite(opened, 'opened.jpg');

% Closing
closed = imclose(image, se);
imwrite(closed, 'closed.jpg');
            </pre>
        </div>

        <!-- 6. TEXTURE ANALYSIS -->
        <h2>Texture Analysis</h2>
        <p>
            <strong>Texture</strong> describes the spatial arrangement of intensity or color patterns in local regions. 
            Texture-based methods aim to quantify these local patterns, enabling image classification, segmentation, and recognition. 
            Two widely studied approaches include:
        </p>
        <ul>
            <li>
                <strong>Gray Level Co-occurrence Matrix (GLCM):</strong><br>
                Captures how frequently pairs of pixel intensities co-occur at a given spatial relationship (e.g., distance and angle). 
                From the GLCM, features like contrast, correlation, energy, and homogeneity can be computed.
            </li>
            <li>
                <strong>Local Binary Patterns (LBP):</strong><br>
                For each pixel, LBP compares intensities of its neighbors to the center pixel, forming a binary code that describes local micro-patterns. 
                LBP is popular for tasks like face recognition and texture classification due to its robustness against illumination changes.
            </li>
        </ul>

        <!-- 7. APPLICATIONS OF LOCAL IMAGE PROCESSING -->
        <h2>Applications of Local Image Processing</h2>
        <p>
            Local transformations are integral to many fields, offering the ability to adapt processing based on local context and structure:
        </p>
        <ul>
            <li>
                <strong>Medical Imaging:</strong> 
                Local filters enhance tumors, blood vessels, or microcalcifications in radiographic or MRI scans, aiding in early detection and diagnosis.
            </li>
            <li>
                <strong>Surveillance Systems:</strong> 
                Movement and edge information extracted at the pixel neighborhood level can be used for motion tracking or anomaly detection.
            </li>
            <li>
                <strong>Document Processing and OCR:</strong> 
                Morphological operations and local thresholding help clean up scanned documents for clearer text recognition.
            </li>
            <li>
                <strong>Industrial Quality Inspection:</strong> 
                Local filters and morphological methods detect surface defects, cracks, or inconsistencies in manufacturing lines.
            </li>
        </ul>

        <!-- 8. CHALLENGES AND CONSIDERATIONS -->
        <h2>Challenges and Considerations</h2>
        <p>
            Despite their versatility, local techniques require careful parameter tuning and an understanding of how the chosen kernel affects the image:
        </p>
        <ul>
            <li>
                <strong>Kernel Size and Shape:</strong> 
                A kernel that is too large may smooth or remove important details, whereas a kernel that is too small may fail to capture relevant structures. 
                Non-square or adaptive kernels can be considered for specialized tasks.
            </li>
            <li>
                <strong>Noise vs. Detail Trade-Off:</strong> 
                Aggressive smoothing can remove critical edges or texture features. 
                Similarly, over-sharpening may amplify noise and introduce artifacts.
            </li>
            <li>
                <strong>Computational Complexity:</strong> 
                Local operations must be applied at every pixel, which can be time-consuming for high-resolution images or real-time applications. 
                Efficient algorithms and parallel processing (e.g., GPU) can help mitigate these costs.
            </li>
            <li>
                <strong>Edge Effects:</strong> 
                When applying a local filter near the borders of an image, the neighborhood extends beyond the image boundaries. 
                Common strategies for handling this include replication, reflection, or zero-padding of border pixels.
            </li>
        </ul>

        <!-- 9. FURTHER LEARNING RESOURCES -->
        <h2>Further Learning Resources</h2>
        <p>
            To explore advanced local image processing techniques and gain practical experience, consider the following resources:
        </p>
        <ul>
            <li><a href="https://opencv.org/">OpenCV - Open-source computer vision library</a></li>
            <li><a href="https://scikit-image.org/">scikit-image - Image processing in Python</a></li>
            <li><a href="https://en.wikipedia.org/wiki/Edge_detection">Edge Detection (Wikipedia)</a> - Overview of diverse edge detection methods</li>
            <li><a href="https://www.kaggle.com/datasets">Kaggle - Image Processing Datasets</a> - Public datasets for experimentation</li>
            <li><em>Digital Image Processing</em> by Gonzalez & Woods - Foundational text on filtering, morphology, and more</li>
        </ul>

        <!-- 10. INTERACTIVE DEMOS -->
        <h2>Interactive Demos</h2>
        <p>Below are live demos illustrating some key local transformations—smoothing, sharpening, edge detection, and morphological operations—directly in the browser.</p>
        
        <div class="demo-toggle" onclick="toggleDemo('demo-smooth-sharpen')">
            <strong>Smoothing &amp; Sharpening Demo</strong>
        </div>
        
      <div id="demo-smooth-sharpen" class="demo-content">
        <p>
          This demo applies a simple <strong>box blur (smoothing)</strong> and/or a <strong>sharpen filter</strong> to the image.
          Adjust the sliders below to see the effect. The kernel size determines how large the neighborhood for the blur is.
        </p>
        <div class="slider-group">
          <input type="checkbox" id="applySmoothing" checked> 
          <label for="applySmoothing">Apply Smoothing (Box Blur)</label>
        </div>
        <div class="slider-group">
          <label for="kernelSize">Kernel Size:</label>
          <input type="range" id="kernelSize" min="1" max="15" value="3">
          <span id="kernelSizeValue">3</span>
        </div>
        <div class="slider-group">
          <input type="checkbox" id="applySharpen"> 
          <label for="applySharpen">Apply Sharpen</label>
        </div>
        <div class="slider-group">
          <label for="sharpenAmount">Sharpen Strength:</label>
          <input type="range" id="sharpenAmount" min="0" max="5" value="1" step="0.1">
          <span id="sharpenValue">1.0</span>
        </div>
        <canvas id="canvasSmoothSharpen" width="600" height="400"></canvas>
      </div>
    
      <div class="demo-toggle" onclick="toggleDemo('demo-edge')">
        <strong>Edge Detection Demo</strong>
      </div>
      <div id="demo-edge" class="demo-content">
        <p>
          This demo applies a simple <strong>Sobel operator</strong> to detect edges and then optionally thresholds the result. 
          Adjust the threshold slider to binarize the edges.
        </p>
        <div class="slider-group">
          <label for="edgeThreshold">Edge Threshold (0-255):</label>
          <input type="range" id="edgeThreshold" min="0" max="255" value="100">
          <span id="edgeThresholdValue">100</span>
          <input type="checkbox" id="applyEdgeThreshold">
          <label for="applyEdgeThreshold">Apply threshold</label>
        </div>
        <canvas id="canvasEdge" width="600" height="400"></canvas>
      </div>
    
      <div class="demo-toggle" onclick="toggleDemo('demo-morph')">
        <strong>Morphological Operations Demo</strong>
      </div>
      <div id="demo-morph" class="demo-content">
        <p>
          This demo first converts the image to binary (using a threshold), then applies either <strong>erosion</strong> or <strong>dilation</strong> using a 
          square structuring element. Move the sliders or switch the operation to see how it affects the binary image.
        </p>
        <div class="slider-group">
          <label for="binaryThreshold">Binarize Threshold (0-255):</label>
          <input type="range" id="binaryThreshold" min="0" max="255" value="128">
          <span id="binaryThresholdValue">128</span>
        </div>
        <div>
          <input type="radio" name="morphOp" id="morphErode" value="erode" checked>
          <label for="morphErode">Erode</label>
          <input type="radio" name="morphOp" id="morphDilate" value="dilate">
          <label for="morphDilate">Dilate</label>
        </div>
        <div class="slider-group">
          <label for="morphKernel">Struct. Elem. Size:</label>
          <input type="range" id="morphKernel" min="1" max="15" value="3">
          <span id="morphKernelValue">3</span>
        </div>
        <canvas id="canvasMorph" width="600" height="400"></canvas>
      </div>
    
      <img id="sourceImage" src="image1.jpeg" style="display:none;" />
    </div>

    <footer>
        <p>&copy; 2025 A. Giuliano Mirabella | <a href="https://github.com/agiulianomirabella">GitHub</a></p>
    </footer>
    <script src="script.js"></script>
    <script>
        /************************************************************************
         * GENERAL SETUP: LOADING THE IMAGE
         ************************************************************************/
        const sourceImg = document.getElementById('sourceImage');
        sourceImg.onload = function() {
          // Once the image is loaded, initialize all demos.
          initSmoothSharpenDemo();
          initEdgeDemo();
          initMorphDemo();
        };
    
        // Helper to toggle the "demo-content" visibility
        function toggleDemo(id) {
          const el = document.getElementById(id);
          if (!el) return;
          el.style.display = (el.style.display === 'block') ? 'none' : 'block';
        }
    
        /************************************************************************
         * 1) SMOOTHING (BOX BLUR) & SHARPENING DEMO
         ************************************************************************/
        function initSmoothSharpenDemo() {
          const canvas = document.getElementById('canvasSmoothSharpen');
          const ctx = canvas.getContext('2d');
    
          // Draw the source image onto the canvas
          canvas.width = sourceImg.width;
          canvas.height = sourceImg.height;
          ctx.drawImage(sourceImg, 0, 0, canvas.width, canvas.height);
    
          // We'll store the "original" image data so we can re-filter from scratch each time
          const originalImageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    
          // Sliders and checkboxes
          const applySmoothing = document.getElementById('applySmoothing');
          const kernelSizeSlider = document.getElementById('kernelSize');
          const kernelSizeValue = document.getElementById('kernelSizeValue');
          const applySharpen = document.getElementById('applySharpen');
          const sharpenAmountSlider = document.getElementById('sharpenAmount');
          const sharpenValue = document.getElementById('sharpenValue');
    
          // Whenever a parameter changes, re-apply
          [applySmoothing, kernelSizeSlider, applySharpen, sharpenAmountSlider].forEach(elem => {
            elem.addEventListener('input', applyFilters);
          });
    
          function applyFilters() {
            // Show current slider values
            kernelSizeValue.textContent = kernelSizeSlider.value;
            sharpenValue.textContent = sharpenAmountSlider.value;
    
            // Start by copying the original pixels
            ctx.putImageData(originalImageData, 0, 0);
            let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            let pixels = imageData.data;
    
            // 1) Smoothing (Box Blur) if checked
            if (applySmoothing.checked) {
              const size = parseInt(kernelSizeSlider.value, 10);
              pixels = boxBlur(pixels, canvas.width, canvas.height, size);
            }
    
            // 2) Sharpening if checked
            if (applySharpen.checked) {
              const amount = parseFloat(sharpenAmountSlider.value);
              pixels = sharpen(pixels, canvas.width, canvas.height, amount);
            }
    
            // Put final result back
            const outImageData = new ImageData(pixels, canvas.width, canvas.height);
            ctx.putImageData(outImageData, 0, 0);
          }
    
          // Immediately apply with default settings
          applyFilters();
        }
    
        /**
         * Simple Box Blur
         * @param {Uint8ClampedArray} inputPixels RGBA pixel data
         * @param {number} width 
         * @param {number} height 
         * @param {number} kernelSize Odd integer recommended
         * @returns {Uint8ClampedArray} new RGBA pixel data
         */
        function boxBlur(inputPixels, width, height, kernelSize) {
          const outputPixels = new Uint8ClampedArray(inputPixels.length);
          const half = Math.floor(kernelSize / 2);
    
          for (let y = 0; y < height; y++) {
            for (let x = 0; x < width; x++) {
    
              let rSum = 0, gSum = 0, bSum = 0;
              let count = 0;
    
              // Sum up the neighboring pixels
              for (let ky = -half; ky <= half; ky++) {
                for (let kx = -half; kx <= half; kx++) {
                  const ny = y + ky;
                  const nx = x + kx;
                  if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
                    const idx = (ny * width + nx) * 4;
                    rSum += inputPixels[idx];
                    gSum += inputPixels[idx + 1];
                    bSum += inputPixels[idx + 2];
                    count++;
                  }
                }
              }
    
              const outIdx = (y * width + x) * 4;
              outputPixels[outIdx] = rSum / count;
              outputPixels[outIdx + 1] = gSum / count;
              outputPixels[outIdx + 2] = bSum / count;
              outputPixels[outIdx + 3] = 255; // fully opaque
            }
          }
    
          return outputPixels;
        }
    
        /**
         * Simple Sharpen filter
         * We use a 3x3 kernel with adjustable center weight
         * Base kernel (amount=1) is:
         * [  0, -1,  0 ]
         * [ -1,  5, -1 ]
         * [  0, -1,  0 ]
         * The 'amount' parameter adjusts the center from 5 up/down.
         */
        function sharpen(inputPixels, width, height, amount=1.0) {
          const outputPixels = new Uint8ClampedArray(inputPixels.length);
          // Weighted kernel:
          const kernel = [
            0, -1, 0,
            -1, 5 * amount, -1,
            0, -1, 0
          ];
          const side = 3;
          const half = Math.floor(side / 2);
    
          for (let y = 0; y < height; y++) {
            for (let x = 0; x < width; x++) {
              let rAcc = 0, gAcc = 0, bAcc = 0;
    
              for (let ky = -half; ky <= half; ky++) {
                for (let kx = -half; kx <= half; kx++) {
                  const ny = y + ky;
                  const nx = x + kx;
                  const kIndex = (ky + half) * side + (kx + half);
    
                  if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
                    const idx = (ny * width + nx) * 4;
                    rAcc += inputPixels[idx] * kernel[kIndex];
                    gAcc += inputPixels[idx + 1] * kernel[kIndex];
                    bAcc += inputPixels[idx + 2] * kernel[kIndex];
                  }
                }
              }
    
              const outIdx = (y * width + x) * 4;
              outputPixels[outIdx] = clamp(rAcc);
              outputPixels[outIdx + 1] = clamp(gAcc);
              outputPixels[outIdx + 2] = clamp(bAcc);
              outputPixels[outIdx + 3] = 255;
            }
          }
    
          return outputPixels;
        }
    
        /************************************************************************
         * 2) EDGE DETECTION (SOBEL) DEMO
         ************************************************************************/
        function initEdgeDemo() {
          const canvas = document.getElementById('canvasEdge');
          const ctx = canvas.getContext('2d');
    
          canvas.width = sourceImg.width;
          canvas.height = sourceImg.height;
          ctx.drawImage(sourceImg, 0, 0, canvas.width, canvas.height);
    
          const originalImageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    
          const edgeThresholdSlider = document.getElementById('edgeThreshold');
          const edgeThresholdValue = document.getElementById('edgeThresholdValue');
          const applyEdgeThreshold = document.getElementById('applyEdgeThreshold');
    
          [edgeThresholdSlider, applyEdgeThreshold].forEach(el => {
            el.addEventListener('input', applyEdgeDetection);
          });
    
          function applyEdgeDetection() {
            edgeThresholdValue.textContent = edgeThresholdSlider.value;
            ctx.putImageData(originalImageData, 0, 0);
            let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    
            let sobelData = sobelOperator(imageData.data, canvas.width, canvas.height);
            
            // If threshold is checked, binarize
            if (applyEdgeThreshold.checked) {
              const t = parseInt(edgeThresholdSlider.value, 10);
              sobelData = threshold(sobelData, canvas.width, canvas.height, t);
            }
    
            const outImageData = new ImageData(sobelData, canvas.width, canvas.height);
            ctx.putImageData(outImageData, 0, 0);
          }
    
          applyEdgeDetection();
        }
    
        /**
         * Sobel operator to detect edges
         * We'll produce a grayscale result for edges
         */
        function sobelOperator(inputPixels, width, height) {
          const output = new Uint8ClampedArray(inputPixels.length);
    
          // Sobel kernels for X and Y
          const gx = [-1,0,1, -2,0,2, -1,0,1];
          const gy = [-1,-2,-1, 0,0,0, 1,2,1];
          const side = 3;
          const half = Math.floor(side/2);
    
          // Convert to grayscale first to simplify (optional but typical)
          // We'll do it inline.
          function grayAt(px, i) {
            // average
            return 0.299 * px[i] + 0.587 * px[i+1] + 0.114 * px[i+2];
          }
    
          for (let y = 0; y < height; y++) {
            for (let x = 0; x < width; x++) {
              let sumX = 0;
              let sumY = 0;
    
              for (let ky = -half; ky <= half; ky++) {
                for (let kx = -half; kx <= half; kx++) {
                  const ny = y + ky;
                  const nx = x + kx;
                  const kIndex = (ky + half) * side + (kx + half);
    
                  if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
                    const idx = (ny * width + nx) * 4;
                    const g = grayAt(inputPixels, idx);
                    sumX += gx[kIndex] * g;
                    sumY += gy[kIndex] * g;
                  }
                }
              }
    
              const magnitude = Math.sqrt(sumX*sumX + sumY*sumY);
              const outIdx = (y * width + x) * 4;
              output[outIdx] = magnitude;
              output[outIdx + 1] = magnitude;
              output[outIdx + 2] = magnitude;
              output[outIdx + 3] = 255;
            }
          }
          return output;
        }
    
        /**
         * Threshold a grayscale image
         */
        function threshold(pixels, width, height, t) {
          const out = new Uint8ClampedArray(pixels.length);
          for (let i = 0; i < pixels.length; i += 4) {
            const val = pixels[i]; // R=G=B for grayscale
            const bin = (val >= t) ? 255 : 0;
            out[i] = bin;
            out[i+1] = bin;
            out[i+2] = bin;
            out[i+3] = 255;
          }
          return out;
        }
    
        /************************************************************************
         * 3) MORPHOLOGICAL DEMO
         ************************************************************************/
        function initMorphDemo() {
          const canvas = document.getElementById('canvasMorph');
          const ctx = canvas.getContext('2d');
    
          canvas.width = sourceImg.width;
          canvas.height = sourceImg.height;
          ctx.drawImage(sourceImg, 0, 0, canvas.width, canvas.height);
    
          const originalImageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    
          const binaryThresholdSlider = document.getElementById('binaryThreshold');
          const binaryThresholdValue = document.getElementById('binaryThresholdValue');
          const morphKernelSlider = document.getElementById('morphKernel');
          const morphKernelValue = document.getElementById('morphKernelValue');
          const morphErode = document.getElementById('morphErode');
          const morphDilate = document.getElementById('morphDilate');
    
          const inputs = [
            binaryThresholdSlider, morphKernelSlider,
            morphErode, morphDilate
          ];
    
          inputs.forEach(el => el.addEventListener('input', applyMorphology));
    
          function applyMorphology() {
            binaryThresholdValue.textContent = binaryThresholdSlider.value;
            morphKernelValue.textContent = morphKernelSlider.value;
    
            // Reset to original
            ctx.putImageData(originalImageData, 0, 0);
            let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    
            // 1) Convert to grayscale + threshold => binary
            const t = parseInt(binaryThresholdSlider.value, 10);
            let binData = threshold(imageData.data, canvas.width, canvas.height, t);
    
            // 2) Apply morphological operation
            const size = parseInt(morphKernelSlider.value, 10);
            let result;
            if (morphErode.checked) {
              result = erode(binData, canvas.width, canvas.height, size);
            } else {
              result = dilate(binData, canvas.width, canvas.height, size);
            }
    
            ctx.putImageData(new ImageData(result, canvas.width, canvas.height), 0, 0);
          }
    
          applyMorphology();
        }
    
        /**
         * Erosion for a binary (0 or 255) image, using a square structuring element.
         */
        function erode(pixels, width, height, kernelSize) {
          const out = new Uint8ClampedArray(pixels.length);
          const half = Math.floor(kernelSize / 2);
    
          for (let y = 0; y < height; y++) {
            for (let x = 0; x < width; x++) {
              // If there's any '0' in the neighborhood, output is '0' (eroded away)
              let minVal = 255;
              for (let ky = -half; ky <= half; ky++) {
                for (let kx = -half; kx <= half; kx++) {
                  const ny = y + ky;
                  const nx = x + kx;
                  if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
                    const idx = (ny * width + nx) * 4;
                    // For binary images R=G=B, just check the red channel
                    if (pixels[idx] < minVal) {
                      minVal = pixels[idx];
                    }
                  } else {
                    // Outside the image, treat it as 0 if you like, 
                    // but typically you might skip or replicate
                    minVal = 0;
                  }
                }
              }
              const outIdx = (y * width + x) * 4;
              // minVal will be 0 if any neighbor is 0
              out[outIdx] = minVal;
              out[outIdx + 1] = minVal;
              out[outIdx + 2] = minVal;
              out[outIdx + 3] = 255;
            }
          }
          return out;
        }
    
        /**
         * Dilation for a binary image, using a square structuring element.
         */
        function dilate(pixels, width, height, kernelSize) {
          const out = new Uint8ClampedArray(pixels.length);
          const half = Math.floor(kernelSize / 2);
    
          for (let y = 0; y < height; y++) {
            for (let x = 0; x < width; x++) {
              // If there's any '255' in the neighborhood, output is '255' (dilated)
              let maxVal = 0;
              for (let ky = -half; ky <= half; ky++) {
                for (let kx = -half; kx <= half; kx++) {
                  const ny = y + ky;
                  const nx = x + kx;
                  if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
                    const idx = (ny * width + nx) * 4;
                    if (pixels[idx] > maxVal) {
                      maxVal = pixels[idx];
                    }
                  }
                }
              }
              const outIdx = (y * width + x) * 4;
              out[outIdx] = maxVal;
              out[outIdx + 1] = maxVal;
              out[outIdx + 2] = maxVal;
              out[outIdx + 3] = 255;
            }
          }
          return out;
        }
    
        /************************************************************************
         * Utility: clamp function for sharpening
         ************************************************************************/
        function clamp(val) {
          return Math.max(0, Math.min(255, val));
        }
    
      </script>
</body>
</html>
