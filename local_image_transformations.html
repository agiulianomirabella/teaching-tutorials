<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Local Image Transformations">
    <meta name="author" content="A. Giuliano Mirabella">
    <title>Local Image Transformations</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Local Image Transformations</h1>
        <p>Understanding pixel neighborhood operations in image processing</p>
    </header>

    <div class="container">
        <!-- 1. WHAT IS LOCAL IMAGE PROCESSING? -->
        <h2>What is Local Image Processing?</h2>
        <p>
            <strong>Local image processing</strong> refers to operations that modify the values of pixels in an image based on information 
            from a small, localized neighborhood or region around each pixel. Unlike <em>global transformations</em>—which apply uniform 
            adjustments across the entire image—local transformations adapt their outputs on a pixel-by-pixel basis, 
            typically guided by the context or features in the pixel’s vicinity.
        </p>
        <p>
            This fine-grained control allows for targeted enhancements, such as noise reduction, edge sharpening, and detailed texture analysis. 
            It is particularly important in scenarios where different parts of the image require different processing strategies, 
            such as in medical imaging (highlighting tumor boundaries), surveillance (motion detection in specific regions), 
            and industrial quality control (detecting defects on assembly lines).
        </p>

        <!-- 2. TYPES OF LOCAL IMAGE PROCESSING TECHNIQUES -->
        <h2>Types of Local Image Processing Techniques</h2>
        <p>
            Common local operations rely on a <strong>moving window</strong> or <strong>kernel</strong> that scans over the image. 
            Within this window, pixels are combined according to a specific rule or formula, and the result is written back to the center pixel location. 
            Below are some core categories:
        </p>
        <ul>
            <li><strong>Filtering:</strong> Enhancing or suppressing specific features, such as edges or noise.</li>
            <li><strong>Edge Detection:</strong> Identifying boundaries between distinct regions in an image.</li>
            <li><strong>Morphological Operations:</strong> Processing binary and grayscale images based on their shape; 
                these techniques are widely used for noise removal, gap filling, and shape analysis.</li>
            <li><strong>Texture Analysis:</strong> Extracting local patterns that help in classification, segmentation, or feature extraction.</li>
        </ul>

        <!-- 3. IMAGE FILTERING -->
        <h2>Image Filtering</h2>
        <p>
            <strong>Filtering</strong> in local image processing involves using a kernel (also known as a filter mask or convolution mask) 
            that is applied to each pixel neighborhood. The kernel dimensions (e.g., 3×3, 5×5) and coefficients determine the effect of the filter. 
            Filtering can be linear (convolution-based) or nonlinear (e.g., median filtering).
        </p>
        <ul>
            <li>
                <strong>Smoothing (Blurring):</strong><br>
                These filters reduce random noise and small-scale details in the image. 
                A <em>Gaussian filter</em> uses a weighted, bell-shaped kernel to give more weight to pixels near the center; 
                a <em>median filter</em> replaces each pixel with the median value of its neighborhood, preserving edges better than simple averaging.
            </li>
            <li>
                <strong>Sharpening (High-Pass Filters):</strong><br>
                Instead of smoothing, sharpening filters emphasize edges and fine details. 
                One basic approach is <em>unsharp masking</em>, which subtracts a blurred version of the image from the original to highlight high-frequency content.
            </li>
            <li>
                <strong>Edge Detection:</strong><br>
                While technically a distinct operation, many edge detectors (Sobel, Prewitt, Laplacian) can be seen as specialized filters 
                that respond strongly to intensity changes in specific orientations.
            </li>
        </ul>

        <!-- Code Tabs: Filtering in Python and MATLAB -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-filtering')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-filtering')">MATLAB</div>
        </div>

        <div id="python-filtering" class="code-block active">
            <pre>
import cv2
import numpy as np

# Load an image in grayscale
image = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)

# Apply Gaussian blur
blurred = cv2.GaussianBlur(image, (5,5), 0)
cv2.imwrite('blurred.jpg', blurred)

# Apply median blur
median_blurred = cv2.medianBlur(image, 5)
cv2.imwrite('median_blurred.jpg', median_blurred)
            </pre>
        </div>

        <div id="matlab-filtering" class="code-block">
            <pre>
% Read the grayscale image
image = imread('image.jpg');
image_gray = rgb2gray(image);

% Apply Gaussian blur
kernel_size = [5 5];
sigma = 0; % Standard deviation, 0 lets MATLAB choose
blurred = imgaussfilt(image_gray, sigma, 'FilterSize', kernel_size);
imwrite(blurred, 'blurred.jpg');

% Apply median filter
median_blurred = medfilt2(image_gray, [5 5]);
imwrite(median_blurred, 'median_blurred.jpg');
            </pre>
        </div>

        <!-- 4. EDGE DETECTION -->
        <h2>Edge Detection</h2>
        <p>
            <strong>Edge detection</strong> identifies significant intensity transitions, typically corresponding to object boundaries 
            or abrupt changes in texture. Accurately detecting edges is foundational for segmentation, feature extraction, and object recognition. 
            Two popular approaches:
        </p>
        <ul>
            <li>
                <strong>Sobel/Prewitt Operators:</strong><br>
                These operators approximate the gradient in the horizontal and vertical directions, 
                combining them to produce an edge map. Sobel uses a larger kernel (3×3) and places more weight on the center pixels, 
                whereas Prewitt uses a simpler kernel.
            </li>
            <li>
                <strong>Canny Edge Detector:</strong><br>
                A multi-stage algorithm including noise reduction (via Gaussian blur), gradient calculation, non-maximum suppression, 
                double thresholding, and edge tracking by hysteresis. Canny is often considered the “gold standard” for edge detection 
                because it reduces false positives while preserving accurate boundaries.
            </li>
        </ul>

        <!-- Code Tabs: Canny Edge Detection in Python and MATLAB -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-canny')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-canny')">MATLAB</div>
        </div>

        <div id="python-canny" class="code-block active">
            <pre>
# Canny Edge Detection
edges = cv2.Canny(image, 50, 150)
cv2.imwrite('edges.jpg', edges)
            </pre>
        </div>

        <div id="matlab-canny" class="code-block">
            <pre>
% Read the image
image = imread('input_image.jpg');

% Convert to grayscale if necessary
if size(image, 3) == 3
    image = rgb2gray(image);
end

% Apply Canny edge detection
edges = edge(image, 'Canny', [0.2 0.6]);

% Save the edge-detected image
imwrite(edges, 'edges.jpg');
            </pre>
        </div>

        <!-- 5. MORPHOLOGICAL OPERATIONS -->
        <h2>Morphological Operations</h2>
        <p>
            <strong>Morphological operations</strong> analyze and process images based on <em>shape</em>. 
            They originated from mathematical morphology and are especially useful for binary images, though they can be extended to grayscale. 
            The key idea is to probe or interact with an image using a <em>structuring element</em> that defines the neighborhood shape.
        </p>
        <ul>
            <li>
                <strong>Erosion:</strong><br>
                Removes pixels on object boundaries if the structuring element cannot fully fit inside the object. 
                Used to eliminate small, unwanted regions or to separate objects that are touching.
            </li>
            <li>
                <strong>Dilation:</strong><br>
                Adds pixels to object boundaries, effectively enlarging the object. 
                Commonly used to fill gaps or holes.
            </li>
            <li>
                <strong>Opening:</strong><br>
                An erosion followed by a dilation. Opening removes small objects or noise 
                while mostly preserving the size and shape of larger objects.
            </li>
            <li>
                <strong>Closing:</strong><br>
                A dilation followed by an erosion, used to fill small holes or gaps within objects 
                without significantly altering their overall shape.
            </li>
        </ul>

        <!-- Code Tabs: Morphological Operations in Python and MATLAB -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-morph')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-morph')">MATLAB</div>
        </div>

        <div id="python-morph" class="code-block active">
            <pre>
import cv2
import numpy as np

image = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)

# Create a 5x5 kernel of ones
kernel = np.ones((5,5), np.uint8)

# Erosion
eroded = cv2.erode(image, kernel, iterations=1)
cv2.imwrite('eroded.jpg', eroded)

# Dilation
dilated = cv2.dilate(image, kernel, iterations=1)
cv2.imwrite('dilated.jpg', dilated)

# Opening
opened = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
cv2.imwrite('opened.jpg', opened)

# Closing
closed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
cv2.imwrite('closed.jpg', closed)
            </pre>
        </div>

        <div id="matlab-morph" class="code-block">
            <pre>
image = imread('image.jpg');
if size(image,3) == 3
    image = rgb2gray(image);
end

% Create a 5x5 structuring element
se = strel('square', 5);

% Erosion
eroded = imerode(image, se);
imwrite(eroded, 'eroded.jpg');

% Dilation
dilated = imdilate(image, se);
imwrite(dilated, 'dilated.jpg');

% Opening
opened = imopen(image, se);
imwrite(opened, 'opened.jpg');

% Closing
closed = imclose(image, se);
imwrite(closed, 'closed.jpg');
            </pre>
        </div>

        <!-- 6. TEXTURE ANALYSIS -->
        <h2>Texture Analysis</h2>
        <p>
            <strong>Texture</strong> describes the spatial arrangement of intensity or color patterns in local regions. 
            Texture-based methods aim to quantify these local patterns, enabling image classification, segmentation, and recognition. 
            Two widely studied approaches include:
        </p>
        <ul>
            <li>
                <strong>Gray Level Co-occurrence Matrix (GLCM):</strong><br>
                Captures how frequently pairs of pixel intensities co-occur at a given spatial relationship (e.g., distance and angle). 
                From the GLCM, features like contrast, correlation, energy, and homogeneity can be computed.
            </li>
            <li>
                <strong>Local Binary Patterns (LBP):</strong><br>
                For each pixel, LBP compares intensities of its neighbors to the center pixel, forming a binary code that describes local micro-patterns. 
                LBP is popular for tasks like face recognition and texture classification due to its robustness against illumination changes.
            </li>
        </ul>

        <!-- 7. APPLICATIONS OF LOCAL IMAGE PROCESSING -->
        <h2>Applications of Local Image Processing</h2>
        <p>
            Local transformations are integral to many fields, offering the ability to adapt processing based on local context and structure:
        </p>
        <ul>
            <li>
                <strong>Medical Imaging:</strong> 
                Local filters enhance tumors, blood vessels, or microcalcifications in radiographic or MRI scans, aiding in early detection and diagnosis.
            </li>
            <li>
                <strong>Surveillance Systems:</strong> 
                Movement and edge information extracted at the pixel neighborhood level can be used for motion tracking or anomaly detection.
            </li>
            <li>
                <strong>Document Processing and OCR:</strong> 
                Morphological operations and local thresholding help clean up scanned documents for clearer text recognition.
            </li>
            <li>
                <strong>Industrial Quality Inspection:</strong> 
                Local filters and morphological methods detect surface defects, cracks, or inconsistencies in manufacturing lines.
            </li>
        </ul>

        <!-- 8. CHALLENGES AND CONSIDERATIONS -->
        <h2>Challenges and Considerations</h2>
        <p>
            Despite their versatility, local techniques require careful parameter tuning and an understanding of how the chosen kernel affects the image:
        </p>
        <ul>
            <li>
                <strong>Kernel Size and Shape:</strong> 
                A kernel that is too large may smooth or remove important details, whereas a kernel that is too small may fail to capture relevant structures. 
                Non-square or adaptive kernels can be considered for specialized tasks.
            </li>
            <li>
                <strong>Noise vs. Detail Trade-Off:</strong> 
                Aggressive smoothing can remove critical edges or texture features. 
                Similarly, over-sharpening may amplify noise and introduce artifacts.
            </li>
            <li>
                <strong>Computational Complexity:</strong> 
                Local operations must be applied at every pixel, which can be time-consuming for high-resolution images or real-time applications. 
                Efficient algorithms and parallel processing (e.g., GPU) can help mitigate these costs.
            </li>
            <li>
                <strong>Edge Effects:</strong> 
                When applying a local filter near the borders of an image, the neighborhood extends beyond the image boundaries. 
                Common strategies for handling this include replication, reflection, or zero-padding of border pixels.
            </li>
        </ul>

        <!-- 9. FURTHER LEARNING RESOURCES -->
        <h2>Further Learning Resources</h2>
        <p>
            To explore advanced local image processing techniques and gain practical experience, consider the following resources:
        </p>
        <ul>
            <li><a href="https://opencv.org/">OpenCV - Open-source computer vision library</a></li>
            <li><a href="https://scikit-image.org/">scikit-image - Image processing in Python</a></li>
            <li><a href="https://en.wikipedia.org/wiki/Edge_detection">Edge Detection (Wikipedia)</a> - Overview of diverse edge detection methods</li>
            <li><a href="https://www.kaggle.com/datasets">Kaggle - Image Processing Datasets</a> - Public datasets for experimentation</li>
            <li><em>Digital Image Processing</em> by Gonzalez & Woods - Foundational text on filtering, morphology, and more</li>
        </ul>
    </div>

    <footer>
        <p>&copy; 2025 A. Giuliano Mirabella | <a href="https://github.com/agmirabella">GitHub</a></p>
    </footer>
    <script src="script.js"></script>
</body>
</html>
