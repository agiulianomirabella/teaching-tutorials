<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Machine Learning in Medical Imaging">
    <meta name="author" content="A. Giuliano Mirabella">
    <title>Machine Learning in Medical Imaging</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Machine Learning in Medical Imaging</h1>
        <p>Exploring the impact of AI and machine learning in healthcare</p>
    </header>

    <div class="container">
        <!-- 1. INTRODUCTION TO MACHINE LEARNING IN MEDICAL IMAGING -->
        <h2>Introduction to Machine Learning in Medical Imaging</h2>
        <p>
            <strong>Machine learning (ML)</strong> and broader artificial intelligence (AI) methodologies are transforming the field of medical imaging, 
            enabling automated image analysis and enhancing diagnostic workflows. 
            By training on vast amounts of data, ML algorithms can detect subtle patterns or anomalies in imaging modalities such as X-ray, CT, MRI, 
            and ultrasound that may be challenging for human observers to see, especially in high-volume or complex cases.
        </p>
        <p>
            From <em>computer-aided diagnosis</em> (CAD) systems that flag suspicious lesions to <em>automated segmentation</em> tools that isolate anatomical structures, 
            machine learning’s impact on medical imaging spans both research and clinical practice. 
            Its ability to continuously learn and adapt (with appropriately curated data) holds promise for <em>personalized treatment</em> 
            and <em>early detection</em> of diseases, ultimately improving patient outcomes.
        </p>

        <!-- 2. WHY USE MACHINE LEARNING IN MEDICAL IMAGING? -->
        <h2>Why Use Machine Learning in Medical Imaging?</h2>
        <p>
            Machine learning offers multiple advantages in the medical imaging domain:
        </p>
        <ul>
            <li>
                <strong>Improved Accuracy:</strong><br>
                Automated tools can reduce inter- and intra-radiologist variability. 
                High-complexity algorithms often detect nuances (e.g., minuscule lesions) that might elude even experienced clinicians.
            </li>
            <li>
                <strong>Automation:</strong><br>
                Time-consuming tasks like <em>bulk segmentation</em> or <em>lesion measurement</em> can be automated, 
                freeing clinicians to focus on complex decision-making and patient care.
            </li>
            <li>
                <strong>Early Detection:</strong><br>
                Subtle indicators of disease progression (e.g., microcalcifications in mammography) can be captured early, 
                when treatment may be more effective and less invasive.
            </li>
            <li>
                <strong>Personalized Treatment:</strong><br>
                ML algorithms can integrate imaging data with patient-specific factors (genetics, comorbidities) 
                to propose targeted therapies, a key step toward precision medicine.
            </li>
        </ul>

        <!-- 3. COMMON MACHINE LEARNING TECHNIQUES IN MEDICAL IMAGING -->
        <h2>Common Machine Learning Techniques in Medical Imaging</h2>
        <p>
            A variety of machine learning paradigms are applied to medical imaging, each with its own strengths and typical use cases.
            Below are some primary categories and their core applications.
        </p>

        <!-- 3.1 SUPERVISED LEARNING -->
        <h3>1. Supervised Learning</h3>
        <p>
            <strong>Supervised learning</strong> algorithms learn patterns from labeled medical images. 
            In radiology, these labels may be diagnoses (e.g., “benign” vs. “malignant”) or measurements (tumor size, disease severity). 
            Once trained, the model can predict these labels for new, unseen images.
        </p>
        <ul>
            <li>
                <strong>Classification:</strong><br>
                Determines the category of a lesion, tissue type, or pathology (e.g., identifying fractures in X-rays, classifying brain tumors in MRI).
            </li>
            <li>
                <strong>Regression:</strong><br>
                Predicts continuous outcomes, such as disease progression index (e.g., measuring the degree of cartilage wear in osteoarthritis).
            </li>
        </ul>

        <!-- Code Tabs: Python and MATLAB (Supervised) -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-supervised')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-supervised')">MATLAB</div>
        </div>

        <div id="python-supervised" class="code-block active">
            <pre>
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# Example: Train a Random Forest classifier
X = np.load('features.npy')  # Pre-extracted features from medical images
y = np.load('labels.npy')    # Corresponding labels (e.g., disease vs. healthy)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

clf = RandomForestClassifier()
clf.fit(X_train, y_train)

# Evaluate on the test set
accuracy = clf.score(X_test, y_test)
print("Test Accuracy:", accuracy)
            </pre>
        </div>

        <div id="matlab-supervised" class="code-block">
            <pre>
% Example: Train a Random Forest classifier

% Load features and labels
load('features.mat'); % Contains 'features' array
load('labels.mat');   % Contains 'labels' array

% Split data into training and testing sets (80-20 split)
cv = cvpartition(labels,'Holdout',0.2);
X_train = features(training(cv),:);
y_train = labels(training(cv));
X_test  = features(test(cv),:);
y_test  = labels(test(cv));

% Train a random forest classifier
numTrees = 100;
rfModel = TreeBagger(numTrees, X_train, y_train, 'Method','classification');

% Predict using the trained model
y_pred = predict(rfModel, X_test);

% Convert predictions to numeric if necessary
y_pred = str2double(y_pred);

% Evaluate performance (e.g., confusion matrix)
confMat = confusionmat(y_test, y_pred);
disp('Confusion Matrix:');
disp(confMat);
            </pre>
        </div>

        <!-- 3.2 UNSUPERVISED LEARNING -->
        <h3>2. Unsupervised Learning</h3>
        <p>
            <strong>Unsupervised learning</strong> identifies patterns in unlabeled image data. 
            It helps in tasks where ground-truth labels are expensive or impractical to obtain, 
            such as clustering large databases of scans for research or discovering novel disease subtypes.
        </p>
        <ul>
            <li>
                <strong>Clustering:</strong><br>
                Groups similar images or regions. For instance, it can cluster tissue patches in histopathology slides.
            </li>
            <li>
                <strong>Dimensionality Reduction:</strong><br>
                Techniques like PCA (Principal Component Analysis) can compress high-dimensional imaging data into fewer components, 
                preserving major variance for subsequent visualization or analysis.
            </li>
        </ul>

        <!-- 3.3 DEEP LEARNING -->
        <h3>3. Deep Learning</h3>
        <p>
            <strong>Deep learning</strong>, a sub-field of machine learning, uses hierarchical layers of artificial neural networks to learn complex patterns directly from raw images. 
            In medical imaging, <em>Convolutional Neural Networks (CNNs)</em> are especially popular for classification, segmentation, and detection tasks.
        </p>
        <ul>
            <li>
                <strong>Convolutional Neural Networks (CNNs):</strong><br>
                Capture spatial hierarchies in images, widely applied in analyzing chest X-rays, mammograms, MRI slices, etc.
            </li>
            <li>
                <strong>Recurrent Neural Networks (RNNs):</strong><br>
                Useful for sequential or time-series data in imaging contexts, such as analyzing temporal changes in ultrasound frames or dynamic contrast-enhanced MRI.
            </li>
            <li>
                <strong>Autoencoders:</strong><br>
                Unsupervised neural models for dimensionality reduction, anomaly detection, and image enhancement (e.g., de-noising CT scans).
            </li>
        </ul>

        <!-- Code Tabs: Python and MATLAB (Deep Learning) -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-deep')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-deep')">MATLAB</div>
        </div>

        <div id="python-deep" class="code-block active">
            <pre>
import tensorflow as tf
from tensorflow.keras import layers

# Simple CNN model for binary classification of medical images
model = tf.keras.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 1)),
    layers.MaxPooling2D((2,2)),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D((2,2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # For binary output
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()
            </pre>
        </div>

        <div id="matlab-deep" class="code-block">
            <pre>
% Simple CNN model for binary classification of medical images

layers = [
    imageInputLayer([128 128 1], 'Name', 'input')
    convolution2dLayer(3,32,'Padding','same','Name','conv1')
    reluLayer('Name','relu1')
    maxPooling2dLayer(2,'Stride',2,'Name','pool1')
    convolution2dLayer(3,64,'Padding','same','Name','conv2')
    reluLayer('Name','relu2')
    maxPooling2dLayer(2,'Stride',2,'Name','pool2')
    fullyConnectedLayer(128,'Name','fc1')
    reluLayer('Name','relu3')
    fullyConnectedLayer(1,'Name','fc2')
    sigmoidLayer('Name','sigmoid')
    classificationLayer('Name','output')];

options = trainingOptions('adam', ...
    'MiniBatchSize', 32, ...
    'MaxEpochs', 10, ...
    'Shuffle','every-epoch', ...
    'Verbose',false, ...
    'Plots','training-progress');

% Example: XTrain is [128, 128, 1, numImages], YTrain is categorical labels
net = trainNetwork(XTrain, YTrain, layers, options);
            </pre>
        </div>

        <!-- 3.4 TRANSFER LEARNING -->
        <h3>4. Transfer Learning</h3>
        <p>
            <strong>Transfer learning</strong> repurposes pre-trained deep networks (e.g., ResNet, VGG) for medical image tasks. 
            By “freezing” early layers and only retraining the final layers on domain-specific data, 
            you can obtain high accuracy with relatively small labeled datasets, which is crucial in clinical contexts.
        </p>

        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-transfer')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-transfer')">MATLAB</div>
        </div>

        <div id="python-transfer" class="code-block active">
            <pre>
from tensorflow.keras.applications import VGG16
from tensorflow.keras import models, layers

# Load pre-trained VGG16 model
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # Freeze base model layers

# Create a new classifier head
x = layers.Flatten()(base_model.output)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dense(1, activation='sigmoid')(x)

model = models.Model(inputs=base_model.input, outputs=x)
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()
            </pre>
        </div>

        <div id="matlab-transfer" class="code-block">
            <pre>
% Load and modify a pre-trained VGG16 for a new classification task

net = vgg16; % Pre-trained on ImageNet
lgraph = layerGraph(net);

% Remove the last 3 layers (fc8, prob, output)
lgraph = removeLayers(lgraph, {'fc8','prob','output'});

% Freeze convolutional layers
for layerIdx = 1:length(lgraph.Layers)
    if isa(lgraph.Layers(layerIdx),'nnet.cnn.layer.Convolution2DLayer')
        lgraph.Layers(layerIdx).WeightLearnRateFactor = 0;
        lgraph.Layers(layerIdx).BiasLearnRateFactor = 0;
    end
end

% Add new classification layers
numClasses = 2; % e.g., "disease" vs "healthy"
newLayers = [
    fullyConnectedLayer(numClasses,'Name','fc8')
    softmaxLayer('Name','softmax')
    classificationLayer('Name','output')];

% Connect the new layers
lgraph = addLayers(lgraph,newLayers);
lgraph = connectLayers(lgraph,'drop7','fc8');

% Prepare training options and data
options = trainingOptions('adam','MiniBatchSize',16,'MaxEpochs',5);

% XTrain: training images, YTrain: labels
trainedNet = trainNetwork(XTrain, YTrain, lgraph, options);
            </pre>
        </div>

        <!-- 4. CHALLENGES IN MEDICAL IMAGING WITH MACHINE LEARNING -->
        <h2>Challenges in Medical Imaging with Machine Learning</h2>
        <p>
            Despite rapid advancements, implementing machine learning in clinical settings encounters several hurdles:
        </p>
        <ul>
            <li>
                <strong>Data Quality and Quantity:</strong><br>
                Effective models require large, well-labeled datasets. 
                Gathering such data in medicine can be difficult, partly due to privacy concerns (HIPAA, GDPR) and resource limitations.
            </li>
            <li>
                <strong>Regulatory Compliance:</strong><br>
                Medical devices and software are subject to stringent regulations (e.g., FDA approval in the U.S.). 
                Proving safety and efficacy via rigorous clinical trials can be time-consuming and expensive.
            </li>
            <li>
                <strong>Model Interpretability:</strong><br>
                Clinicians often require explainable AI solutions that highlight why a particular region or lesion led to a specific diagnosis.
            </li>
            <li>
                <strong>Generalization Across Populations:</strong><br>
                Models trained on data from one region or demographic may not perform equally well across different clinical sites, imaging devices, or patient populations.
            </li>
        </ul>

        <!-- 5. APPLICATIONS OF MACHINE LEARNING IN MEDICAL IMAGING -->
        <h2>Applications of Machine Learning in Medical Imaging</h2>
        <p>
            The versatility of machine learning techniques has led to widespread adoption across multiple imaging domains:
        </p>
        <ul>
            <li>
                <strong>Cancer Detection:</strong><br>
                Early detection of breast cancer in mammograms or lung nodules in CT scans, assisting oncologists in making timely treatment decisions.
            </li>
            <li>
                <strong>Retinal Disease Screening:</strong><br>
                Automated analysis of fundus images to diagnose diabetic retinopathy, glaucoma, and other vision-threatening conditions.
            </li>
            <li>
                <strong>Brain Imaging:</strong><br>
                Identifying areas affected by stroke, tumors, or neurodegenerative diseases (Alzheimer’s, Parkinson’s) via MRI or fMRI scans.
            </li>
            <li>
                <strong>3D Reconstruction and Surgical Planning:</strong><br>
                Creating patient-specific 3D models from CT/MRI data to guide surgeons and reduce intraoperative uncertainties.
            </li>
        </ul>

        <!-- 6. POPULAR DATASETS FOR MEDICAL IMAGING -->
        <h2>Popular Datasets for Medical Imaging</h2>
        <p>
            Publicly available datasets foster innovation by enabling benchmarking and collaboration. Some notable resources include:
        </p>
        <ul>
            <li><a href="https://www.kaggle.com/datasets">Kaggle Medical Datasets</a> – Various imaging challenges and competitions.</li>
            <li><a href="https://nihcc.app.box.com/v/ChestXray-NIHCC">NIH Chest X-ray Dataset</a> – A large set of chest X-ray images for pneumonia and other conditions.</li>
            <li><a href="https://www.brats2020.org/">BraTS Brain Tumor Segmentation</a> – Benchmarking dataset focusing on segmentation of brain tumors in MRI.</li>
            <li><a href="https://openneuro.org/">OpenNeuro MRI Datasets</a> – MRI and fMRI data for neuroscientific research.</li>
        </ul>

        <!-- 7. FURTHER LEARNING RESOURCES -->
        <h2>Further Learning Resources</h2>
        <p>
            To further expand your knowledge of machine learning in medical imaging and AI-driven healthcare, consider the following:
        </p>
        <ul>
            <li><a href="https://www.tensorflow.org/">TensorFlow</a> – Popular machine learning framework from Google, with extensive community tutorials.</li>
            <li><a href="https://pytorch.org/">PyTorch</a> – A deep learning library by Meta (Facebook) known for its flexibility and dynamic computation graphs.</li>
            <li><a href="https://radiopaedia.org/">Radiopaedia</a> – Comprehensive reference for radiological images and case studies.</li>
            <li><a href="https://www.coursera.org/specializations/deep-learning">Coursera - Deep Learning Specialization</a> – Courses designed by Andrew Ng, covering fundamentals of neural networks and advanced topics.</li>
            <li><em>Deep Learning for Medical Image Analysis</em> by Zhou et al. – A specialized text covering recent advances and clinical applications of deep learning in medical imaging.</li>
        </ul>
    </div>

    <footer>
        <p>&copy; 2025 <a href="https://personal.us.es/amirabella/">A. Giuliano Mirabella</a></p>
    </footer>
    <script src="script.js"></script>
</body>
</html>
