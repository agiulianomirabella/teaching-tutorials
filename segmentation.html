<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Segmentation Techniques in Image Processing">
    <meta name="author" content="A. Giuliano Mirabella">
    <title>Segmentation</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Segmentation</h1>
        <p>Understanding image segmentation methods and their broad applications</p>
    </header>

    <div class="container">
        <!-- 1. WHAT IS IMAGE SEGMENTATION? -->
        <h2>What is Image Segmentation?</h2>
        <p>
            <strong>Image segmentation</strong> is the process of partitioning an image into coherent, meaningful regions. 
            In essence, segmentation algorithms seek to simplify or change the representation of an image to make it more understandable and easier to analyze. 
            Rather than considering every pixel individually, segmentation allows us to group pixels that share certain characteristics (e.g., intensity, color, texture) 
            into larger regions that may correspond to objects, organs, or areas of interest.
        </p>
        <p>
            Segmentation is a cornerstone of many computer vision and image processing pipelines—particularly in <em>medical imaging</em>, 
            <em>autonomous systems</em>, and <em>remote sensing</em>. By isolating structures like tumors, roads, or defects, we can perform higher-level tasks 
            such as object recognition, volumetric measurement, or anomaly detection.
        </p>

        <!-- 2. WHY IS SEGMENTATION IMPORTANT? -->
        <h2>Why is Segmentation Important?</h2>
        <p>
            Segmentation drastically reduces the complexity of subsequent image analysis steps and forms the backbone of many critical applications:
        </p>
        <ul>
            <li>
                <strong>Object Detection:</strong><br>
                Precise segmentation helps in accurately localizing and classifying objects within an image or video, 
                which is vital for surveillance, robotics, and industrial inspection.
            </li>
            <li>
                <strong>Medical Diagnosis:</strong><br>
                By delineating structures such as organs or lesions in medical scans (CT, MRI, Ultrasound), segmentation aids in treatment planning, 
                disease monitoring, and surgical guidance.
            </li>
            <li>
                <strong>Autonomous Systems:</strong><br>
                Self-driving cars, drones, and service robots rely heavily on robust segmentation to understand road layouts, detect pedestrians, and navigate safely.
            </li>
            <li>
                <strong>Quality Control:</strong><br>
                Automated inspection lines in manufacturing utilize segmentation to highlight defective items, chips, or irregularities.
            </li>
        </ul>

        <!-- 3. TYPES OF IMAGE SEGMENTATION TECHNIQUES -->
        <h2>Types of Image Segmentation Techniques</h2>
        <p>
            Segmentation techniques can be broadly classified according to the core principle or algorithmic approach they employ. 
            Below are several common categories:
        </p>

        <!-- 3.1 THRESHOLDING-BASED SEGMENTATION -->
        <h3>1. Thresholding-Based Segmentation</h3>
        <p>
            <strong>Thresholding</strong> is one of the simplest yet most widely used segmentation strategies. 
            It converts an image from grayscale (or color) to a binary image, differentiating foreground (objects) from the background 
            by setting a cut-off intensity value (the threshold).
        </p>
        <ul>
            <li>
                <strong>Global Thresholding:</strong><br>
                Uses a single threshold value for the entire image, typically determined by analyzing the overall histogram. 
                Most effective when the foreground and background intensities are well-separated.
            </li>
            <li>
                <strong>Adaptive (Local) Thresholding:</strong><br>
                Computes threshold values for small sub-regions in the image. 
                Useful when illumination or contrast varies across different parts of the image.
            </li>
            <li>
                <strong>Otsu’s Method:</strong><br>
                An automatic approach that selects an “optimal” global threshold by minimizing the within-class variance of the two segmented groups. 
                Often used as a robust default method in applications where no prior knowledge of threshold is available.
            </li>
        </ul>

        <!-- Code Tabs: Python and MATLAB (Otsu) -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-otsu')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-otsu')">MATLAB</div>
        </div>

        <div id="python-otsu" class="code-block active">
            <pre>
import cv2

# Load grayscale image
image = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)

# Apply Otsu's thresholding
_, thresholded = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
cv2.imwrite('thresholded.jpg', thresholded)
            </pre>
        </div>

        <div id="matlab-otsu" class="code-block">
            <pre>
% Load grayscale image
image = imread('image.jpg');
grayImage = rgb2gray(image);  % Convert to grayscale if needed

% Apply Otsu's thresholding
level = graythresh(grayImage);      % Compute Otsu's threshold (normalized 0-1)
thresholded = imbinarize(grayImage, level);  % Apply threshold

% Convert logical to uint8 for saving (0 or 255)
thresholded = uint8(thresholded) * 255;
imwrite(thresholded, 'thresholded.jpg');
            </pre>
        </div>

        <!-- 3.2 EDGE-BASED SEGMENTATION -->
        <h3>2. Edge-Based Segmentation</h3>
        <p>
            <strong>Edge-based</strong> methods locate objects by identifying discontinuities or sharp intensity transitions in an image. 
            Edges often mark the boundaries between distinct objects or regions.
        </p>
        <ul>
            <li>
                <strong>Sobel Operator:</strong><br>
                Computes intensity gradients in the horizontal and vertical directions. 
                The resulting gradient magnitude highlights edges.
            </li>
            <li>
                <strong>Canny Edge Detector:</strong><br>
                A multi-stage algorithm that includes noise reduction, gradient calculation, non-maximum suppression, 
                double-thresholding, and edge tracking by hysteresis. 
                Considered one of the more robust classical edge detection methods.
            </li>
        </ul>

        <!-- Code Tabs: Python and MATLAB (Canny) -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-canny')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-canny')">MATLAB</div>
        </div>

        <div id="python-canny" class="code-block active">
            <pre>
# Canny Edge Detection
edges = cv2.Canny(image, 50, 150)
cv2.imwrite('edges.jpg', edges)
            </pre>
        </div>

        <div id="matlab-canny" class="code-block">
            <pre>
% Apply Canny edge detection
edges = edge(grayImage, 'Canny', [50 150]/255);

% Convert logical result to uint8 (0 or 255) for saving
edges = uint8(edges) * 255;
imwrite(edges, 'edges.jpg');
            </pre>
        </div>

        <!-- 3.3 REGION-BASED SEGMENTATION -->
        <h3>3. Region-Based Segmentation</h3>
        <p>
            <strong>Region-based</strong> methods group neighboring pixels into regions based on similarity criteria (e.g., intensity, texture, color). 
            Unlike edge-based approaches, which focus on boundaries, region-based segmentation attempts to determine the homogeneous areas directly.
        </p>
        <ul>
            <li>
                <strong>Region Growing:</strong><br>
                Starts from one or more “seed” pixels and expands outward as long as neighboring pixels fulfill a similarity condition (like intensity difference). 
                This simple approach can be effective if seeds and criteria are well chosen.
            </li>
            <li>
                <strong>Watershed Algorithm:</strong><br>
                Conceptualizes the grayscale image as a topographic surface. 
                Regions “flood” from the minima, and barriers (watershed lines) form where floods from different minima meet. 
                Particularly effective in scenarios where clear intensity ridges separate distinct objects.
            </li>
        </ul>

        <!-- Code Tabs: Python and MATLAB (Simple Watershed Example) -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-water')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-water')">MATLAB</div>
        </div>

        <div id="python-water" class="code-block active">
            <pre>
# Watershed Algorithm (simplified illustration)
import cv2

# Assume 'image' is a loaded BGR image
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
# Basic threshold for foreground detection
_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

# Save binary result (in practice, additional steps needed for watershed)
cv2.imwrite('watershed_result.jpg', binary)
            </pre>
        </div>

        <div id="matlab-water" class="code-block">
            <pre>
% Apply Otsu's thresholding with inverse binary mode
level = graythresh(grayImage);
binary = imbinarize(grayImage, level);
binary = ~binary;  % invert binary (like THRESH_BINARY_INV)

% Save result
binary_uint8 = uint8(binary) * 255;
imwrite(binary_uint8, 'watershed_result.jpg');
            </pre>
        </div>

        <!-- 3.4 CLUSTERING-BASED SEGMENTATION -->
        <h3>4. Clustering-Based Segmentation</h3>
        <p>
            <strong>Clustering-based</strong> segmentation is an unsupervised learning approach, commonly used when the number of classes or segments is known in advance 
            (or we wish to explore multiple possible segmentations). It groups pixels into clusters based on their feature vectors (e.g., intensity, color, texture).
        </p>
        <ul>
            <li>
                <strong>K-Means Clustering:</strong><br>
                Partitions data into \(k\) clusters by minimizing the within-cluster sum of squares. 
                Often used for simple color-based segmentation or to separate an image into regions of similar intensity.
            </li>
            <li>
                <strong>Gaussian Mixture Models (GMM):</strong><br>
                Models the data distribution with multiple Gaussian components. Each pixel is assigned to the component (cluster) that maximizes its posterior probability.
            </li>
        </ul>

        <!-- Code Tabs: Python and MATLAB (K-Means Example) -->
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-clustering')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-clustering')">MATLAB</div>
        </div>

        <div id="python-clustering" class="code-block active">
            <pre>
from sklearn.cluster import KMeans
import numpy as np

# Assume 'image' is a 2D grayscale array
pixels = image.reshape(-1, 1)  # Flatten to (N,1)

# K-Means with 3 clusters
kmeans = KMeans(n_clusters=3, random_state=42).fit(pixels)
labels = kmeans.labels_.reshape(image.shape)

# 'labels' now contains values 0,1,2 representing the cluster each pixel belongs to
            </pre>
        </div>

        <div id="matlab-clustering" class="code-block">
            <pre>
% Flatten the image into a column vector
pixels = double(image(:));

% Apply K-Means clustering with 3 clusters
n_clusters = 3;
[idx, ~] = kmeans(pixels, n_clusters);

% Reshape the clustered labels back to the original image dimensions
segmented_image = reshape(idx, size(image));
            </pre>
        </div>

        <!-- 3.5 DEEP LEARNING-BASED SEGMENTATION -->
        <h3>5. Deep Learning-Based Segmentation</h3>
        <p>
            With the advancement of deep neural networks, <strong>deep learning-based</strong> methods have dramatically improved segmentation accuracy and robustness, 
            often surpassing traditional approaches in challenging, real-world scenarios.
        </p>
        <ul>
            <li>
                <strong>U-Net:</strong><br>
                Originally designed for biomedical image segmentation. Its symmetrical encoder-decoder architecture learns both context and precise localization.
            </li>
            <li>
                <strong>Mask R-CNN:</strong><br>
                An extension of Faster R-CNN that performs instance segmentation. 
                It detects objects and predicts a binary mask for each instance, widely used in applications like autonomous driving and robotics.
            </li>
            <li>
                <strong>Fully Convolutional Networks (FCN):</strong><br>
                Replace the fully connected layers in standard CNNs with convolutional ones, enabling end-to-end pixel-wise classification.
            </li>
        </ul>
        <p>
            Although these methods typically require large labeled datasets and significant computational resources (often GPUs), 
            they are currently the state-of-the-art for many complex segmentation tasks.
        </p>

        <!-- 4. APPLICATIONS OF IMAGE SEGMENTATION -->
        <h2>Applications of Image Segmentation</h2>
        <p>
            Segmentation is essential across a multitude of domains:
        </p>
        <ul>
            <li>
                <strong>Medical Imaging:</strong><br>
                Automatic detection and delineation of tumors, organs, or lesions in modalities such as MRI, CT, and ultrasound.
            </li>
            <li>
                <strong>Autonomous Vehicles:</strong><br>
                Lane detection, pedestrian recognition, and obstacle avoidance rely on consistent segmentation in real-time.
            </li>
            <li>
                <strong>Satellite Imaging:</strong><br>
                Land cover classification, vegetation mapping, and urban development monitoring leverage segmentation of large-scale remote-sensing imagery.
            </li>
            <li>
                <strong>Security Systems:</strong><br>
                Face, fingerprint, or iris segmentation is critical for biometric authentication and identification.
            </li>
        </ul>

        <!-- 5. CHALLENGES AND CONSIDERATIONS -->
        <h2>Challenges and Considerations</h2>
        <p>
            Despite the variety of techniques, segmentation remains a challenging field:
        </p>
        <ul>
            <li>
                <strong>Varying Illumination and Contrast:</strong><br>
                Changes in lighting can significantly affect pixel intensities, complicating thresholding and region-based approaches.
            </li>
            <li>
                <strong>Complex Shapes and Textures:</strong><br>
                Real-world objects often lack uniform color or intensity; advanced methods or deep learning may be required to segment them accurately.
            </li>
            <li>
                <strong>High Computational Cost:</strong><br>
                Processing large or high-resolution images can be expensive, especially for sophisticated algorithms (e.g., watershed, 3D volumetric data).
            </li>
            <li>
                <strong>Choosing the Right Method:</strong><br>
                No single technique is universally best. The choice depends on the nature of the images, noise levels, domain requirements, and computational constraints.
            </li>
        </ul>

        <!-- 6. FURTHER LEARNING RESOURCES -->
        <h2>Further Learning Resources</h2>
        <p>
            For those interested in diving deeper into image segmentation, the following resources offer tutorials, libraries, and theoretical foundations:
        </p>
        <ul>
            <li><a href="https://opencv.org/">OpenCV - Computer vision library</a> – Provides ready-to-use segmentation functions.</li>
            <li><a href="https://scikit-image.org/">scikit-image - Image processing in Python</a> – Includes thresholding, region growing, and more.</li>
            <li><a href="https://www.coursera.org/learn/digital-image-processing">Coursera - Digital Image Processing</a> – In-depth online courses covering traditional and modern segmentation methods.</li>
            <li><a href="https://en.wikipedia.org/wiki/Image_segmentation">Image Segmentation (Wikipedia)</a> – A high-level overview and links to research papers.</li>
            <li><em>Digital Image Processing</em> by Gonzalez & Woods – A classic textbook containing fundamental segmentation algorithms and theory.</li>
        </ul>
    </div>

    <footer>
        <p>&copy; 2025 A. Giuliano Mirabella | <a href="https://github.com/agmirabella">GitHub</a></p>
    </footer>
    <script src="script.js"></script>
</body>
</html>
