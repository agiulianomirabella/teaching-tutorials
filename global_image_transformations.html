<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Global Image Transformations">
    <meta name="author" content="A. Giuliano Mirabella">
    <title>Global Image Transformations</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Global Image Transformations</h1>
        <p>Understanding transformations applied to the entire image</p>
    </header>

    <div class="container">
        <!-- 1. WHAT ARE GLOBAL IMAGE TRANSFORMATIONS? -->
        <h2>What are Global Image Transformations?</h2>
        <p>
            <strong>Global image transformations</strong> are operations or functions that act uniformly on all pixels in an image. 
            Unlike local or neighborhood-based operations (e.g., filtering with a small kernel), global transformations apply consistent rules 
            across every pixel in the image without focusing on specific local features or regions. 
            These transformations can be broadly categorized into:
        </p>
        <ul>
            <li><strong>Geometric Transformations:</strong> Spatial rearrangements (e.g., scaling, rotation, translation).</li>
            <li><strong>Intensity Transformations:</strong> Adjustments of pixel intensity values (e.g., contrast stretching, thresholding).</li>
            <li><strong>Frequency Domain Transformations:</strong> Techniques that operate on the frequency representation of the image 
                (e.g., Fourier transforms for global filtering).
            </li>
        </ul>
        <p>
            Global transformations play a foundational role in many image processing and computer vision tasks, including 
            image alignment, enhancement, and feature analysis. Their mathematical underpinnings often involve linear algebra, 
            signal processing, and geometric modeling, making them a crucial area of study for researchers and practitioners alike.
        </p>

        <!-- 2. TYPES OF GLOBAL TRANSFORMATIONS -->
        <h2>Types of Global Transformations</h2>
        <p>
            Although there are many ways to categorize global transformations, the following three types are among the most common:
        </p>
        <ul>
            <li>
                <strong>Geometric Transformations:</strong><br>
                Operations that change the spatial position of pixels in a consistent manner. Common examples include:
                <ul>
                    <li><em>Scaling</em> (enlarging or shrinking the image).</li>
                    <li><em>Rotation</em> (about a pivot point, typically the image center).</li>
                    <li><em>Translation</em> (shifting pixels by a fixed offset in x and y directions).</li>
                    <li><em>Affine transformations</em> (more general transformations preserving parallelism, e.g., shear and reflection).</li>
                    <li><em>Perspective transformations</em> (changing the viewpoint, which can mimic 3D-like rotations in 2D space).</li>
                </ul>
            </li>
            <li>
                <strong>Intensity Transformations:</strong><br>
                Adjust pixel intensity values directly, without altering spatial locations. 
                Examples include contrast enhancements, thresholding, or histogram modifications.
            </li>
            <li>
                <strong>Frequency Domain Transformations:</strong><br>
                Convert the image to its frequency representation (e.g., using the 2D Fourier transform) 
                and apply filters or transformations globally in the frequency space. 
                After modification, the image is transformed back to the spatial domain.
            </li>
        </ul>

        <!-- 3. GEOMETRIC TRANSFORMATIONS -->
        <h2>Geometric Transformations</h2>
        <p>
            <strong>Geometric transformations</strong> reshape the spatial layout of an image. These transformations are critical in tasks like 
            image registration (aligning images from different modalities or time points), panoramas (stitching multiple images into one), 
            and correcting geometric distortions (e.g., camera lens distortion). Some key geometric operations include:
        </p>
        <ul>
            <li>
                <strong>Scaling:</strong> 
                Enlarges or reduces the image size by applying a uniform or non-uniform scaling factor along the x and y axes. 
                Scaling can introduce interpolation artifacts if the transformation requires synthesizing new pixel values.
            </li>
            <li>
                <strong>Rotation:</strong> 
                Rotates the image around a user-defined pivot (commonly the center). 
                Rotation is often used to correct orientation or perform rotational data augmentation in machine learning contexts.
            </li>
            <li>
                <strong>Translation:</strong> 
                Shifts the entire image in the plane by fixed offsets (\(\Delta x\) and \(\Delta y\)). 
                Although straightforward, translation is frequently employed in image registration or region-of-interest alignment.
            </li>
            <li>
                <strong>Affine Transformations:</strong> 
                Include rotation, scaling, shear, and reflection, but preserve parallel lines. 
                The transformation can be described by a 2×3 matrix that is applied to each pixel coordinate.
            </li>
            <li>
                <strong>Perspective Transformations (Projective Transformations):</strong> 
                Provide a way to mimic the effect of viewing an image plane from different angles. 
                Straight lines remain straight, but parallel lines may converge or diverge to reflect changes in perspective.
            </li>
        </ul>

        <!-- 4. INTENSITY TRANSFORMATIONS -->
        <h2>Intensity Transformations</h2>
        <p>
            Intensity-based transformations adjust the pixel values to enhance visibility, contrast, or segmentation. 
            They do not alter pixel <em>positions</em> but rather modify pixel <em>values</em>. Key methods include:
        </p>
        <ul>
            <li>
                <strong>Contrast Stretching:</strong><br>
                Re-maps the intensity values to fill a broader range (e.g., from the minimum and maximum in the original image to 0–255). 
                This can help reveal subtle features in under- or over-exposed images.
            </li>
            <li>
                <strong>Histogram Equalization:</strong><br>
                A popular technique to enhance global contrast by redistributing intensity values based on the image’s histogram. 
                The goal is to make the intensities follow a uniform or target distribution, often resulting in improved visual clarity.
            </li>
            <li>
                <strong>Thresholding:</strong><br>
                Sets a particular intensity level as a cutoff, converting a grayscale image into a binary (black-and-white) representation. 
                Widely used in image segmentation for extracting objects from the background.
            </li>
            <li>
                <strong>Log and Power-Law (Gamma) Transformations:</strong><br>
                Used for correcting illumination problems or enhancing certain features. 
                Log transformations can highlight low-intensity values, while power-law transforms (gamma correction) can address brightness differences.
            </li>
        </ul>

        <!-- 5. FREQUENCY DOMAIN TRANSFORMATIONS -->
        <h2>Frequency Domain Transformations</h2>
        <p>
            Global transformations can also be performed in the <strong>frequency domain</strong>, especially when broad filtering actions are required:
        </p>
        <ul>
            <li>
                <strong>Fourier Transform:</strong> 
                The 2D Discrete Fourier Transform (DFT) represents the image as a sum of sinusoidal components at various frequencies. 
                Global low-pass or high-pass filters (e.g., removing all frequencies above a certain threshold) can be applied 
                to achieve smoothing or edge enhancement when converted back to the spatial domain.
            </li>
            <li>
                <strong>Global Frequency Filters:</strong> 
                Such as band-pass filters that can isolate specific frequency bands, 
                or notch filters that remove periodic noise (e.g., lines or repetitive patterns).
            </li>
        </ul>
        <p>
            Although this article focuses primarily on spatial-domain transformations, frequency-domain approaches remain vital for comprehensive image processing.
        </p>

        <!-- 6. MATHEMATICAL REPRESENTATION OF TRANSFORMATIONS -->
        <h2>Mathematical Representation of Transformations</h2>
        <p>
            Many global transformations—particularly geometric ones—can be concisely expressed using matrices or functions that map old coordinates \((x, y)\) 
            to new coordinates \((x', y')\). For a 2D affine transformation, this mapping can be written as:
        </p>
        <pre>
[x']   [a11  a12  tx] [x]
[y'] = [a21  a22  ty] [y]
[1 ]   [  0    0   1] [1]
        </pre>
        <p>
            Where the 2×2 submatrix (\(a_{11}\), \(a_{12}\), \(a_{21}\), \(a_{22}\)) handles linear transformations 
            (rotation, scaling, shear), and \((tx, ty)\) handles translation. Below are code snippets demonstrating 
            rotation using OpenCV in Python and MATLAB's <em>imwarp</em> function.
        </p>
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-rotation')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-rotation')">MATLAB</div>
        </div>

        <div id="python-rotation" class="code-block active">
            <pre>
# Example: Rotation matrix
import cv2
import numpy as np

image = cv2.imread('image.jpg')
rows, cols = image.shape[:2]

# Rotation matrix: rotate by 45 degrees around the center
M = cv2.getRotationMatrix2D((cols/2, rows/2), 45, 1)
rotated_image = cv2.warpAffine(image, M, (cols, rows))

cv2.imshow('Rotated Image', rotated_image)
cv2.waitKey(0)
cv2.destroyAllWindows()
            </pre>
        </div>

        <div id="matlab-rotation" class="code-block">
            <pre>
% Example: Rotation matrix
image = imread('image.jpg');
[rows, cols, ~] = size(image);

% Rotation angle (in degrees) and scaling factor
theta = 45;
scale = 1;

% Compute the rotation matrix around the image center
% (Note: affine2d uses 3x3 transformations in homogeneous coordinates)
cx = cols/2;
cy = rows/2;

% Translation to move rotation center to origin
T1 = [1 0 -cx; 0 1 -cy; 0 0 1];
% Rotation and scale
R = [cosd(theta)*scale, -sind(theta)*scale, 0;
     sind(theta)*scale,  cosd(theta)*scale, 0;
     0,                  0,                 1];
% Translation back
T2 = [1 0 cx; 0 1 cy; 0 0 1];

% Combine transformations
M = T2 * R * T1;

% Warp the image
rotated_image = imwarp(image, affine2d(M), 'OutputView', imref2d([rows cols]));

figure;
subplot(1,2,1); imshow(image); title('Original Image');
subplot(1,2,2); imshow(rotated_image); title('Rotated Image');
            </pre>
        </div>

        <!-- 7. APPLICATION OF GLOBAL TRANSFORMATIONS -->
        <h2>Application of Global Transformations</h2>
        <p>
            Global transformations find use in numerous domains, including:
        </p>
        <ul>
            <li>
                <strong>Medical Imaging:</strong> 
                To align or register images from different modalities (e.g., CT, MRI, PET) or from different time points, 
                enabling clinicians to compare anatomical or functional changes accurately.
            </li>
            <li>
                <strong>Computer Vision:</strong> 
                Transformations help normalize data for machine learning models, perform data augmentation, or track objects 
                whose orientation or position changes over time.
            </li>
            <li>
                <strong>Image Enhancement:</strong> 
                Adjusting contrast or perspective can improve the visual interpretability of images, 
                making subsequent analysis steps (e.g., segmentation, feature extraction) more robust.
            </li>
            <li>
                <strong>Art and Design:</strong> 
                Photographers and graphic designers frequently use geometric and intensity transformations to correct images, 
                change aesthetics, or create effects.
            </li>
        </ul>

        <!-- 8. CHALLENGES AND CONSIDERATIONS -->
        <h2>Challenges and Considerations</h2>
        <p>
            While global transformations can be powerful, they also pose certain challenges:
        </p>
        <ul>
            <li>
                <strong>Interpolation and Resampling:</strong> 
                When pixels are relocated (as in scaling or rotation), new pixel values often need to be interpolated. 
                Methods like nearest-neighbor, bilinear, or bicubic interpolation can introduce artifacts (e.g., aliasing or blurriness).
            </li>
            <li>
                <strong>Computational Cost:</strong> 
                Large images or high-resolution 3D volumes (e.g., in medical imaging) make global transformations computationally expensive, 
                requiring optimized algorithms or hardware acceleration.
            </li>
            <li>
                <strong>Feature Preservation:</strong> 
                Excessive transformations can degrade details or features important for diagnosis or machine learning tasks. 
                Care must be taken to avoid losing crucial information.
            </li>
            <li>
                <strong>Global vs. Local Requirements:</strong> 
                Not all imaging tasks benefit from a single global transformation. Localized deformations or segment-based analyses may be necessary 
                if different regions in the image require different transformations or enhancements.
            </li>
        </ul>

        <!-- 9. FURTHER LEARNING RESOURCES -->
        <h2>Further Learning Resources</h2>
        <p>
            To deepen your knowledge of global image transformations and their practical implementations, explore the following:
        </p>
        <ul>
            <li><a href="https://docs.opencv.org/">OpenCV Documentation</a> – Comprehensive reference for image processing in C++ and Python.</li>
            <li><a href="https://scipy.org/">SciPy</a> – A Python-based ecosystem for scientific computing, offering modules like <code>scipy.ndimage</code> for advanced transformations.</li>
            <li><a href="https://en.wikipedia.org/wiki/Image_transformation">Image Transformation (Wikipedia)</a> – A general overview and historical context.</li>
            <li><a href="https://www.kaggle.com/datasets">Kaggle</a> – Large repository of datasets that can be used to practice or benchmark transformation techniques.</li>
            <li><em>Digital Image Processing</em> by Gonzalez & Woods – A classic textbook discussing many of these transformations and their mathematical foundations.</li>
        </ul>

        <!-- 10. INTERACTIVE DEMOS -->
        <h2>10. Interactive Demos</h2>
        <p>
            Below are live demos illustrating some key global transformations—geometric, intensity, and frequency-domain—directly in the browser. 
            Click each section to expand and interact with the sliders. Feel free to modify or integrate these examples in your projects.
        </p>

        <!-- 10.1: Geometric Transformations Demo -->
        <div class="demo-toggle" onclick="toggleDemo('demo-geometric')">
            <strong>Geometric Transformations Demo (Click to Expand/Collapse)</strong>
        </div>
        <div id="demo-geometric" class="demo-content">
            <p>Use the sliders to rotate, scale, and translate the image on an HTML canvas.</p>
            <label>
              Rotation (degrees): 
              <input type="range" id="rotation" min="0" max="360" value="0" />
            </label>
            <br />
            <label>
              Scale: 
              <input type="range" id="scale" min="10" max="200" value="100" />
            </label>
            <br />
            <label>
              Translate X: 
              <input type="range" id="translateX" min="-200" max="200" value="0" />
            </label>
            <br />
            <label>
              Translate Y: 
              <input type="range" id="translateY" min="-200" max="200" value="0" />
            </label>
            <canvas id="canvasGeometric" width="600" height="400"></canvas>
        </div>

        <!-- 10.2: Intensity Transformations Demo -->
        <div class="demo-toggle" onclick="toggleDemo('demo-intensity')">
            <strong>Intensity Transformations Demo (Click to Expand/Collapse)</strong>
        </div>
        <div id="demo-intensity" class="demo-content">
            <p>Adjust brightness, contrast, or apply thresholding to convert the image into black and white.</p>
            <div class="slider-group">
              <label for="brightness">Brightness:</label>
              <input type="range" id="brightness" min="-100" max="100" value="0" />
            </div>
            <div class="slider-group">
              <label for="contrast">Contrast:</label>
              <input type="range" id="contrast" min="0" max="200" value="100" />
            </div>
            <div class="slider-group">
              <label for="threshold">Threshold (0–255):</label>
              <input type="range" id="threshold" min="0" max="255" value="128" />
              <input type="checkbox" id="applyThreshold"/> <span>Apply threshold</span>
            </div>
            <canvas id="canvasIntensity" width="640" height="426"></canvas>
        </div>

        <!-- 10.3: Frequency Domain Demo -->
        <div class="demo-toggle" onclick="toggleDemo('demo-frequency')">
            <strong>Frequency Domain Demo (Click to Expand/Collapse)</strong>
        </div>
        <div id="demo-frequency" class="demo-content">
            <p>
                This example uses <strong>OpenCV.js</strong> to apply a simple low-pass filter in the frequency domain. 
                Move the “Cutoff Frequency” slider to see how it removes (or retains) high-frequency details.
            </p>
            <label for="cutoff">Cutoff Frequency (% of max):</label>
            <input type="range" id="cutoff" min="0" max="100" value="50"/>
            <br />
            <!-- Two canvases: one hidden for input, one for output -->
            <canvas id="canvasFreqInput" style="display:none;"></canvas>
            <canvas id="canvasFreqOutput"></canvas>
        </div>
    </div> <!-- /.container -->

    <footer>
        <p>&copy; 2025 A. Giuliano Mirabella | <a href="https://github.com/agmirabella">GitHub</a></p>
    </footer>

    <!-- Load OpenCV.js (no 'async' to ensure it's ready when we need it) -->
    <script src="opencv.js"></script>

    <!-- Wrap ALL code that references cv inside onRuntimeInitialized -->
    <script>
    cv.onRuntimeInitialized = () => {

      /*****************************************************************
       * Simple tab switcher for the code snippets in the article
       *****************************************************************/
      function switchCode(tabId) {
        let allTabs = document.querySelectorAll(".code-tab");
        let allBlocks = document.querySelectorAll(".code-block");
        allTabs.forEach(t => t.classList.remove("active"));
        allBlocks.forEach(b => b.classList.remove("active"));

        document.getElementById(tabId).classList.add("active");
        event.target.classList.add("active");
      }

      /*****************************************************************
       * Collapsible toggles for the interactive demos
       *****************************************************************/
      function toggleDemo(demoId) {
        const elem = document.getElementById(demoId);
        elem.style.display = (elem.style.display === "block") ? "none" : "block";
      }

      /*****************************************************************
       * 1) GEOMETRIC TRANSFORMATIONS DEMO
       *****************************************************************/
      const canvasGeom = document.getElementById("canvasGeometric");
      let ctxGeom;
      let imgGeom;
      if (canvasGeom) {
        ctxGeom = canvasGeom.getContext("2d");

        // Sliders
        const rotationInput  = document.getElementById("rotation");
        const scaleInput     = document.getElementById("scale");
        const translateXInput= document.getElementById("translateX");
        const translateYInput= document.getElementById("translateY");

        // Load an example image
        imgGeom = new Image();
        imgGeom.crossOrigin = "anonymous";
        imgGeom.src = "image1.jpeg";

        imgGeom.onload = () => drawGeometric();

        // Attach events
        [rotationInput, scaleInput, translateXInput, translateYInput].forEach(input => {
          input.addEventListener("input", drawGeometric);
        });

        function drawGeometric() {
          // Clear canvas
          ctxGeom.clearRect(0, 0, canvasGeom.width, canvasGeom.height);

          // Get slider values
          const rotationDeg = parseFloat(rotationInput.value);
          const scaleVal    = parseFloat(scaleInput.value) / 100;
          const translateX  = parseFloat(translateXInput.value);
          const translateY  = parseFloat(translateYInput.value);

          // Move origin to canvas center
          ctxGeom.save();
          ctxGeom.translate(canvasGeom.width / 2, canvasGeom.height / 2);

          // Apply transformations
          ctxGeom.rotate((Math.PI / 180) * rotationDeg);
          ctxGeom.scale(scaleVal, scaleVal);
          ctxGeom.translate(translateX, translateY);

          // Draw image
          ctxGeom.drawImage(imgGeom, -imgGeom.width / 2, -imgGeom.height / 2);

          ctxGeom.restore();
        }
      }

      /*****************************************************************
       * 2) INTENSITY TRANSFORMATIONS DEMO
       *****************************************************************/
      const canvasInt = document.getElementById("canvasIntensity");
      let ctxInt;
      let imgInt;
      if (canvasInt) {
        ctxInt = canvasInt.getContext("2d");

        const brightnessInput    = document.getElementById("brightness");
        const contrastInput      = document.getElementById("contrast");
        const thresholdInput     = document.getElementById("threshold");
        const applyThresholdCheckbox = document.getElementById("applyThreshold");

        imgInt = new Image();
        imgInt.crossOrigin = "anonymous";
        imgInt.src = "image1.jpeg";

        imgInt.onload = function() {
          canvasInt.width = imgInt.width;
          canvasInt.height = imgInt.height;
          drawIntensity();
        };

        [brightnessInput, contrastInput, thresholdInput, applyThresholdCheckbox].forEach(el => {
          el.addEventListener("input", drawIntensity);
        });

        function drawIntensity() {
          // Draw the original image
          ctxInt.drawImage(imgInt, 0, 0, canvasInt.width, canvasInt.height);

          const brightness   = parseInt(brightnessInput.value);
          const contrastVal  = parseInt(contrastInput.value);
          const threshold    = parseInt(thresholdInput.value);
          const applyThresh  = applyThresholdCheckbox.checked;

          let imageData = ctxInt.getImageData(0, 0, canvasInt.width, canvasInt.height);
          let data = imageData.data;

          // Contrast factor: 100 => 1.0, 200 => 2.0, etc.
          const contrastFactor = contrastVal / 100;

          for (let i = 0; i < data.length; i += 4) {
            let r = data[i];
            let g = data[i+1];
            let b = data[i+2];
            // alpha channel is data[i+3], typically unchanged

            // Brightness shift
            r += brightness;
            g += brightness;
            b += brightness;

            // Contrast scale around midpoint (128)
            r = ((r - 128) * contrastFactor) + 128;
            g = ((g - 128) * contrastFactor) + 128;
            b = ((b - 128) * contrastFactor) + 128;

            // Optional threshold (convert to grayscale first)
            if (applyThresh) {
              let gray = 0.299*r + 0.587*g + 0.114*b; 
              if (gray < threshold) {
                r = g = b = 0;
              } else {
                r = g = b = 255;
              }
            }

            // Clamp to [0,255]
            data[i]   = Math.max(0, Math.min(255, r));
            data[i+1] = Math.max(0, Math.min(255, g));
            data[i+2] = Math.max(0, Math.min(255, b));
          }
          ctxInt.putImageData(imageData, 0, 0);
        }
      }

      /*****************************************************************
       * 3) FREQUENCY DOMAIN DEMO (requires OpenCV.js)
       *****************************************************************/
      let srcMat, canvasFreqIn, canvasFreqOut;
      if (document.getElementById("canvasFreqInput")) {
        canvasFreqIn = document.getElementById("canvasFreqInput");
        canvasFreqOut= document.getElementById("canvasFreqOutput");

        let cutoffSlider = document.getElementById("cutoff");

        const freqImg = new Image();
        freqImg.crossOrigin = "anonymous";
        freqImg.src = "image1.jpeg";

        freqImg.onload = function() {
          canvasFreqIn.width  = freqImg.width;
          canvasFreqIn.height = freqImg.height;
          canvasFreqOut.width = freqImg.width;
          canvasFreqOut.height= freqImg.height;
          let ctxFreqIn = canvasFreqIn.getContext("2d");
          ctxFreqIn.drawImage(freqImg, 0, 0);

          // Now that OpenCV is ready, create srcMat:
          srcMat = new cv.Mat();
          // Initialize:
          cv.imshow("canvasFreqInput", srcMat); // not strictly necessary
          srcMat = cv.imread(canvasFreqIn);

          applyFrequencyFilter();
        };

        // Listen for slider changes
        cutoffSlider.addEventListener("input", applyFrequencyFilter);

        function applyFrequencyFilter() {
          if (!srcMat || !cv || !cv.Mat) return;
          let cutoffVal = parseInt(cutoffSlider.value);

          let grayMat = new cv.Mat();
          cv.cvtColor(srcMat, grayMat, cv.COLOR_RGBA2GRAY);

          // Convert to 32F
          let floatMat = new cv.Mat();
          grayMat.convertTo(floatMat, cv.CV_32FC1);

          // DFT
          let dftMat = new cv.Mat();
          cv.dft(floatMat, dftMat, cv.DFT_COMPLEX_OUTPUT);

          // Build mask for low-pass
          let rows = dftMat.rows, cols = dftMat.cols;
          let radius = (cutoffVal / 100) * (Math.min(rows, cols) / 2);

          let mask = new cv.Mat.zeros(rows, cols, dftMat.type());
          for (let r = 0; r < rows; r++) {
            for (let c = 0; c < cols; c++) {
              let dist = Math.sqrt(Math.pow(r - rows/2, 2) + Math.pow(c - cols/2, 2));
              if (dist < radius) {
                // Set real=1, imag=1 in mask
                mask.floatPtr(r, c)[0] = 1.0;
                mask.floatPtr(r, c)[1] = 1.0;
              }
            }
          }
          // Multiply
          cv.multiply(dftMat, mask, dftMat);

          // IDFT
          let idftMat = new cv.Mat();
          cv.idft(dftMat, idftMat, cv.DFT_REAL_OUTPUT + cv.DFT_SCALE);

          // Convert to 8U
          let outMat = new cv.Mat();
          idftMat.convertTo(outMat, cv.CV_8UC1);

          // Display
          cv.imshow("canvasFreqOutput", outMat);

          // Cleanup
          grayMat.delete();
          floatMat.delete();
          dftMat.delete();
          mask.delete();
          idftMat.delete();
          outMat.delete();
        }
      }

      // Expose helper functions on window if needed:
      window.switchCode = switchCode;
      window.toggleDemo = toggleDemo;
    };
    </script>
    <script src="script.js"></script>
</body>
</html>
