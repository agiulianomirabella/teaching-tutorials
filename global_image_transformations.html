<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Global Image Transformations">
    <meta name="author" content="A. Giuliano Mirabella">
    <title>Global Image Transformations</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Global Image Transformations</h1>
        <p>Understanding transformations applied to the entire image</p>
    </header>

    <div class="container">
        <!-- 1. WHAT ARE GLOBAL IMAGE TRANSFORMATIONS? -->
        <h2>What are Global Image Transformations?</h2>
        <p>
            <strong>Global image transformations</strong> are operations or functions that act uniformly on all pixels in an image. 
            Unlike local or neighborhood-based operations (e.g., filtering with a small kernel), global transformations apply consistent rules 
            across every pixel in the image without focusing on specific local features or regions. 
            These transformations can be broadly categorized into:
        </p>
        <ul>
            <li><strong>Geometric Transformations:</strong> Spatial rearrangements (e.g., scaling, rotation, translation).</li>
            <li><strong>Intensity Transformations:</strong> Adjustments of pixel intensity values (e.g., contrast stretching, thresholding).</li>
            <li><strong>Frequency Domain Transformations:</strong> Techniques that operate on the frequency representation of the image 
                (e.g., Fourier transforms for global filtering).
            </li>
        </ul>
        <p>
            Global transformations play a foundational role in many image processing and computer vision tasks, including 
            image alignment, enhancement, and feature analysis. Their mathematical underpinnings often involve linear algebra, 
            signal processing, and geometric modeling, making them a crucial area of study for researchers and practitioners alike.
        </p>

        <!-- 2. TYPES OF GLOBAL TRANSFORMATIONS -->
        <h2>Types of Global Transformations</h2>
        <p>
            Although there are many ways to categorize global transformations, the following three types are among the most common:
        </p>
        <ul>
            <li>
                <strong>Geometric Transformations:</strong><br>
                Operations that change the spatial position of pixels in a consistent manner. Common examples include:
                <ul>
                    <li><em>Scaling</em> (enlarging or shrinking the image).</li>
                    <li><em>Rotation</em> (about a pivot point, typically the image center).</li>
                    <li><em>Translation</em> (shifting pixels by a fixed offset in x and y directions).</li>
                    <li><em>Affine transformations</em> (more general transformations preserving parallelism, e.g., shear and reflection).</li>
                    <li><em>Perspective transformations</em> (changing the viewpoint, which can mimic 3D-like rotations in 2D space).</li>
                </ul>
            </li>
            <li>
                <strong>Intensity Transformations:</strong><br>
                Adjust pixel intensity values directly, without altering spatial locations. 
                Examples include contrast enhancements, thresholding, or histogram modifications.
            </li>
            <li>
                <strong>Frequency Domain Transformations:</strong><br>
                Convert the image to its frequency representation (e.g., using the 2D Fourier transform) 
                and apply filters or transformations globally in the frequency space. 
                After modification, the image is transformed back to the spatial domain.
            </li>
        </ul>

        <!-- 3. GEOMETRIC TRANSFORMATIONS -->
        <h2>Geometric Transformations</h2>
        <p>
            <strong>Geometric transformations</strong> reshape the spatial layout of an image. These transformations are critical in tasks like 
            image registration (aligning images from different modalities or time points), panoramas (stitching multiple images into one), 
            and correcting geometric distortions (e.g., camera lens distortion). Some key geometric operations include:
        </p>
        <ul>
            <li>
                <strong>Scaling:</strong> 
                Enlarges or reduces the image size by applying a uniform or non-uniform scaling factor along the x and y axes. 
                Scaling can introduce interpolation artifacts if the transformation requires synthesizing new pixel values.
            </li>
            <li>
                <strong>Rotation:</strong> 
                Rotates the image around a user-defined pivot (commonly the center). 
                Rotation is often used to correct orientation or perform rotational data augmentation in machine learning contexts.
            </li>
            <li>
                <strong>Translation:</strong> 
                Shifts the entire image in the plane by fixed offsets (\(\Delta x\) and \(\Delta y\)). 
                Although straightforward, translation is frequently employed in image registration or region-of-interest alignment.
            </li>
            <li>
                <strong>Affine Transformations:</strong> 
                Include rotation, scaling, shear, and reflection, but preserve parallel lines. 
                The transformation can be described by a 2×3 matrix that is applied to each pixel coordinate.
            </li>
            <li>
                <strong>Perspective Transformations (Projective Transformations):</strong> 
                Provide a way to mimic the effect of viewing an image plane from different angles. 
                Straight lines remain straight, but parallel lines may converge or diverge to reflect changes in perspective.
            </li>
        </ul>

        <!-- 4. INTENSITY TRANSFORMATIONS -->
        <h2>Intensity Transformations</h2>
        <p>
            Intensity-based transformations adjust the pixel values to enhance visibility, contrast, or segmentation. 
            They do not alter pixel <em>positions</em> but rather modify pixel <em>values</em>. Key methods include:
        </p>
        <ul>
            <li>
                <strong>Contrast Stretching:</strong><br>
                Re-maps the intensity values to fill a broader range (e.g., from the minimum and maximum in the original image to 0–255). 
                This can help reveal subtle features in under- or over-exposed images.
            </li>
            <li>
                <strong>Histogram Equalization:</strong><br>
                A popular technique to enhance global contrast by redistributing intensity values based on the image’s histogram. 
                The goal is to make the intensities follow a uniform or target distribution, often resulting in improved visual clarity.
            </li>
            <li>
                <strong>Thresholding:</strong><br>
                Sets a particular intensity level as a cutoff, converting a grayscale image into a binary (black-and-white) representation. 
                Widely used in image segmentation for extracting objects from the background.
            </li>
            <li>
                <strong>Log and Power-Law (Gamma) Transformations:</strong><br>
                Used for correcting illumination problems or enhancing certain features. 
                Log transformations can highlight low-intensity values, while power-law transforms (gamma correction) can address brightness differences.
            </li>
        </ul>

        <!-- 5. FREQUENCY DOMAIN TRANSFORMATIONS -->
        <h2>Frequency Domain Transformations</h2>
        <p>
            Global transformations can also be performed in the <strong>frequency domain</strong>, especially when broad filtering actions are required:
        </p>
        <ul>
            <li>
                <strong>Fourier Transform:</strong> 
                The 2D Discrete Fourier Transform (DFT) represents the image as a sum of sinusoidal components at various frequencies. 
                Global low-pass or high-pass filters (e.g., removing all frequencies above a certain threshold) can be applied 
                to achieve smoothing or edge enhancement when converted back to the spatial domain.
            </li>
            <li>
                <strong>Global Frequency Filters:</strong> 
                Such as band-pass filters that can isolate specific frequency bands, 
                or notch filters that remove periodic noise (e.g., lines or repetitive patterns).
            </li>
        </ul>
        <p>
            Although this article focuses primarily on spatial-domain transformations, frequency-domain approaches remain vital for comprehensive image processing.
        </p>

        <!-- 6. MATHEMATICAL REPRESENTATION OF TRANSFORMATIONS -->
        <h2>Mathematical Representation of Transformations</h2>
        <p>
            Many global transformations—particularly geometric ones—can be concisely expressed using matrices or functions that map old coordinates \((x, y)\) 
            to new coordinates \((x', y')\). For a 2D affine transformation, this mapping can be written as:
        </p>
        <pre>
[x']   [a11  a12  tx] [x]
[y'] = [a21  a22  ty] [y]
[1 ]   [  0    0   1] [1]
        </pre>
        <p>
            Where the 2×2 submatrix (\(a_{11}\), \(a_{12}\), \(a_{21}\), \(a_{22}\)) handles linear transformations 
            (rotation, scaling, shear), and \((tx, ty)\) handles translation. Below are code snippets demonstrating 
            rotation using OpenCV in Python and MATLAB's <em>imwarp</em> function.
        </p>
        <div class="code-tabs">
            <div class="code-tab active" onclick="switchCode('python-rotation')">Python</div>
            <div class="code-tab" onclick="switchCode('matlab-rotation')">MATLAB</div>
        </div>

        <div id="python-rotation" class="code-block active">
            <pre>
# Example: Rotation matrix
import cv2
import numpy as np

image = cv2.imread('image.jpg')
rows, cols = image.shape[:2]

# Rotation matrix: rotate by 45 degrees around the center
M = cv2.getRotationMatrix2D((cols/2, rows/2), 45, 1)
rotated_image = cv2.warpAffine(image, M, (cols, rows))

cv2.imshow('Rotated Image', rotated_image)
cv2.waitKey(0)
cv2.destroyAllWindows()
            </pre>
        </div>

        <div id="matlab-rotation" class="code-block">
            <pre>
% Example: Rotation matrix
image = imread('image.jpg');
[rows, cols, ~] = size(image);

% Rotation angle (in degrees) and scaling factor
theta = 45;
scale = 1;

% Compute the rotation matrix around the image center
% (Note: affine2d uses 3x3 transformations in homogeneous coordinates)
cx = cols/2;
cy = rows/2;

% Translation to move rotation center to origin
T1 = [1 0 -cx; 0 1 -cy; 0 0 1];
% Rotation and scale
R = [cosd(theta)*scale, -sind(theta)*scale, 0;
     sind(theta)*scale,  cosd(theta)*scale, 0;
     0,                  0,                 1];
% Translation back
T2 = [1 0 cx; 0 1 cy; 0 0 1];

% Combine transformations
M = T2 * R * T1;

% Warp the image
rotated_image = imwarp(image, affine2d(M), 'OutputView', imref2d([rows cols]));

figure;
subplot(1,2,1); imshow(image); title('Original Image');
subplot(1,2,2); imshow(rotated_image); title('Rotated Image');
            </pre>
        </div>

        <!-- 7. APPLICATION OF GLOBAL TRANSFORMATIONS -->
        <h2>Application of Global Transformations</h2>
        <p>
            Global transformations find use in numerous domains, including:
        </p>
        <ul>
            <li>
                <strong>Medical Imaging:</strong> 
                To align or register images from different modalities (e.g., CT, MRI, PET) or from different time points, 
                enabling clinicians to compare anatomical or functional changes accurately.
            </li>
            <li>
                <strong>Computer Vision:</strong> 
                Transformations help normalize data for machine learning models, perform data augmentation, or track objects 
                whose orientation or position changes over time.
            </li>
            <li>
                <strong>Image Enhancement:</strong> 
                Adjusting contrast or perspective can improve the visual interpretability of images, 
                making subsequent analysis steps (e.g., segmentation, feature extraction) more robust.
            </li>
            <li>
                <strong>Art and Design:</strong> 
                Photographers and graphic designers frequently use geometric and intensity transformations to correct images, 
                change aesthetics, or create effects.
            </li>
        </ul>

        <!-- 8. CHALLENGES AND CONSIDERATIONS -->
        <h2>Challenges and Considerations</h2>
        <p>
            While global transformations can be powerful, they also pose certain challenges:
        </p>
        <ul>
            <li>
                <strong>Interpolation and Resampling:</strong> 
                When pixels are relocated (as in scaling or rotation), new pixel values often need to be interpolated. 
                Methods like nearest-neighbor, bilinear, or bicubic interpolation can introduce artifacts (e.g., aliasing or blurriness).
            </li>
            <li>
                <strong>Computational Cost:</strong> 
                Large images or high-resolution 3D volumes (e.g., in medical imaging) make global transformations computationally expensive, 
                requiring optimized algorithms or hardware acceleration.
            </li>
            <li>
                <strong>Feature Preservation:</strong> 
                Excessive transformations can degrade details or features important for diagnosis or machine learning tasks. 
                Care must be taken to avoid losing crucial information.
            </li>
            <li>
                <strong>Global vs. Local Requirements:</strong> 
                Not all imaging tasks benefit from a single global transformation. Localized deformations or segment-based analyses may be necessary 
                if different regions in the image require different transformations or enhancements.
            </li>
        </ul>

        <!-- 9. FURTHER LEARNING RESOURCES -->
        <h2>Further Learning Resources</h2>
        <p>
            To deepen your knowledge of global image transformations and their practical implementations, explore the following:
        </p>
        <ul>
            <li><a href="https://docs.opencv.org/">OpenCV Documentation</a> – Comprehensive reference for image processing in C++ and Python.</li>
            <li><a href="https://scipy.org/">SciPy</a> – A Python-based ecosystem for scientific computing, offering modules like <code>scipy.ndimage</code> for advanced transformations.</li>
            <li><a href="https://en.wikipedia.org/wiki/Image_transformation">Image Transformation (Wikipedia)</a> – A general overview and historical context.</li>
            <li><a href="https://www.kaggle.com/datasets">Kaggle</a> – Large repository of datasets that can be used to practice or benchmark transformation techniques.</li>
            <li><em>Digital Image Processing</em> by Gonzalez & Woods – A classic textbook discussing many of these transformations and their mathematical foundations.</li>
        </ul>

        <!-- 10. INTERACTIVE DEMOS -->
        <h2>10. Interactive Demos</h2>
        <p>
            Below are live demos illustrating some key global transformations—geometric, intensity, and frequency-domain—directly in the browser.
            Click each section to expand and interact with the sliders.
        </p>

        <!-- 10.1: Geometric Transformations Demo -->
        <div class="demo-toggle" onclick="toggleDemo('demo-geometric')">
            <strong>Geometric Transformations Demo (Click to Expand/Collapse)</strong>
        </div>
        <div id="demo-geometric" class="demo-content">
            <p>Use the sliders to rotate, scale, and translate the image.</p>
            <label>
              Rotation (degrees): 
              <input type="range" id="rotation" min="0" max="360" value="0" />
            </label>
            <br />
            <label>
              Scale: 
              <input type="range" id="scale" min="10" max="200" value="100" />
            </label>
            <br />
            <label>
              Translate X: 
              <input type="range" id="translateX" min="-200" max="200" value="0" />
            </label>
            <br />
            <label>
              Translate Y: 
              <input type="range" id="translateY" min="-200" max="200" value="0" />
            </label>
            <canvas id="canvasGeometric" width="600" height="400"></canvas>
        </div>

        <!-- 10.2: Intensity Transformations Demo -->
        <div class="demo-toggle" onclick="toggleDemo('demo-intensity')">
            <strong>Intensity Transformations Demo (Click to Expand/Collapse)</strong>
        </div>
        <div id="demo-intensity" class="demo-content">
            <p>Adjust brightness, contrast, or apply thresholding to convert the image into black and white.</p>
            <div class="slider-group">
              <label for="brightness">Brightness:</label>
              <input type="range" id="brightness" min="-100" max="100" value="0" />
            </div>
            <div class="slider-group">
              <label for="contrast">Contrast:</label>
              <input type="range" id="contrast" min="0" max="200" value="100" />
            </div>
            <div class="slider-group">
              <label for="threshold">Threshold (0–255):</label>
              <input type="range" id="threshold" min="0" max="255" value="128" />
              <input type="checkbox" id="applyThreshold"/> <span>Apply threshold</span>
            </div>
            <canvas id="canvasIntensity" width="640" height="426"></canvas>
        </div>

        <!-- 10.3: Frequency Domain Demo -->
        <div class="demo-toggle" onclick="toggleDemo('demo-frequency')">
            <strong>Frequency Domain Demo (Click to Expand/Collapse)</strong>
        </div>
        <div id="demo-frequency" class="demo-content">
            <p>
                In this example you can apply a simple low-pass filter in the frequency domain. 
                Move the “Cutoff Frequency” slider to see how it removes (or retains) high-frequency details.
            </p>
            <label for="cutoff">Cutoff Frequency (% of max):</label>
            <input type="range" id="cutoff" min="0" max="100" value="20"/>
            <br />
            <!-- Two canvases: one hidden for input, one for output -->
            <canvas id="canvasFreqInput" style="display:none;"></canvas>
            <canvas id="canvasFreqOutput"></canvas>
        </div>
    </div>

    <footer>
        <p>&copy; 2025 A. Giuliano Mirabella | <a href="https://github.com/agiulianomirabella">GitHub</a></p>
    </footer>
    <script src="script.js"></script>

    <script>
      /*****************************************************************
       * 1) GEOMETRIC TRANSFORMATIONS DEMO
       *****************************************************************/
      const canvasGeom = document.getElementById("canvasGeometric");
      let ctxGeom;
      let imgGeom;
      if (canvasGeom) {
        ctxGeom = canvasGeom.getContext("2d");
    
        // Sliders
        const rotationInput  = document.getElementById("rotation");
        const scaleInput     = document.getElementById("scale");
        const translateXInput= document.getElementById("translateX");
        const translateYInput= document.getElementById("translateY");
    
        // Load an example image
        imgGeom = new Image();
        imgGeom.src = "image1.jpeg";
    
        imgGeom.onload = () => drawGeometric();
    
        // Attach events
        [rotationInput, scaleInput, translateXInput, translateYInput].forEach(input => {
          input.addEventListener("input", drawGeometric);
        });
    
        function drawGeometric() {
          // Clear canvas
          ctxGeom.clearRect(0, 0, canvasGeom.width, canvasGeom.height);
    
          // Get slider values
          const rotationDeg = parseFloat(rotationInput.value);
          const scaleVal    = parseFloat(scaleInput.value) / 100;
          const translateX  = parseFloat(translateXInput.value);
          const translateY  = parseFloat(translateYInput.value);
    
          // Move origin to canvas center
          ctxGeom.save();
          ctxGeom.translate(canvasGeom.width / 2, canvasGeom.height / 2);
    
          // Apply transformations
          ctxGeom.rotate((Math.PI / 180) * rotationDeg);
          ctxGeom.scale(scaleVal, scaleVal);
          ctxGeom.translate(translateX, translateY);
    
          // Draw image
          ctxGeom.drawImage(imgGeom, -imgGeom.width / 2, -imgGeom.height / 2);
    
          ctxGeom.restore();
        }
      }
    
      /*****************************************************************
       * 2) INTENSITY TRANSFORMATIONS DEMO
       *****************************************************************/
      const canvasInt = document.getElementById("canvasIntensity");
      let ctxInt;
      let imgInt;
      if (canvasInt) {
        ctxInt = canvasInt.getContext("2d");
    
        const brightnessInput    = document.getElementById("brightness");
        const contrastInput      = document.getElementById("contrast");
        const thresholdInput     = document.getElementById("threshold");
        const applyThresholdCheckbox = document.getElementById("applyThreshold");
    
        imgInt = new Image();
        imgInt.src = "image1.jpeg";
    
        imgInt.onload = function() {
          canvasInt.width = imgInt.width;
          canvasInt.height = imgInt.height;
          drawIntensity();
        };
    
        [brightnessInput, contrastInput, thresholdInput, applyThresholdCheckbox].forEach(el => {
          el.addEventListener("input", drawIntensity);
        });
    
        function drawIntensity() {
          // Draw the original image
          ctxInt.drawImage(imgInt, 0, 0, canvasInt.width, canvasInt.height);
    
          const brightness   = parseInt(brightnessInput.value);
          const contrastVal  = parseInt(contrastInput.value);
          const threshold    = parseInt(thresholdInput.value);
          const applyThresh  = applyThresholdCheckbox.checked;
    
          let imageData = ctxInt.getImageData(0, 0, canvasInt.width, canvasInt.height);
          let data = imageData.data;
    
          // Contrast factor: 100 => 1.0, 200 => 2.0, etc.
          const contrastFactor = contrastVal / 100;
    
          for (let i = 0; i < data.length; i += 4) {
            let r = data[i];
            let g = data[i+1];
            let b = data[i+2];
            // alpha channel is data[i+3], typically unchanged
    
            // Brightness shift
            r += brightness;
            g += brightness;
            b += brightness;
    
            // Contrast scale around midpoint (128)
            r = ((r - 128) * contrastFactor) + 128;
            g = ((g - 128) * contrastFactor) + 128;
            b = ((b - 128) * contrastFactor) + 128;
    
            // Optional threshold (convert to grayscale first)
            if (applyThresh) {
              let gray = 0.299*r + 0.587*g + 0.114*b; 
              if (gray < threshold) {
                r = g = b = 0;
              } else {
                r = g = b = 255;
              }
            }
    
            // Clamp to [0,255]
            data[i]   = Math.max(0, Math.min(255, r));
            data[i+1] = Math.max(0, Math.min(255, g));
            data[i+2] = Math.max(0, Math.min(255, b));
          }
          ctxInt.putImageData(imageData, 0, 0);
        }
      }
    
    /*****************************************************************
    * 3) FREQUENCY DOMAIN DEMO
    *****************************************************************/
    // -------------------------------------------
    // 1D FFT Implementation (Cooley-Tukey)
    // -------------------------------------------
    // Returns two arrays: [Re[], Im[]]
    function fft1D(real, imag) {
      const n = real.length;
      if (n <= 1) return [real, imag];

      // Bit-reversal permutation
      let j = 0;
      for (let i = 0; i < n; i++) {
        if (i < j) {
          [real[i], real[j]] = [real[j], real[i]];
          [imag[i], imag[j]] = [imag[j], imag[i]];
        }
        let m = n >> 1;
        while (j >= m && m > 0) {
          j -= m;
          m >>= 1;
        }
        j += m;
      }

      // Cooley-Tukey
      for (let size = 2; size <= n; size <<= 1) {
        const halfsize = size >> 1;
        const tablestep = (2 * Math.PI) / size;
        for (let i = 0; i < n; i += size) {
          for (let k = 0; k < halfsize; k++) {
            const angle = tablestep * k;
            const wr = Math.cos(angle);
            const wi = -Math.sin(angle);
            const re = real[i + k + halfsize];
            const im = imag[i + k + halfsize];
            const tr = wr * re - wi * im;
            const ti = wr * im + wi * re;
            real[i + k + halfsize] = real[i + k] - tr;
            imag[i + k + halfsize] = imag[i + k] - ti;
            real[i + k] += tr;
            imag[i + k] += ti;
          }
        }
      }

      return [real, imag];
    }

    // -------------------------------------------
    // 1D Inverse FFT
    // -------------------------------------------

    function padToPowerOfTwo(arr) {
      const n = arr.length;
      const nextPow2 = Math.pow(2, Math.ceil(Math.log2(n)));
      if (n < nextPow2) {
        arr = arr.concat(new Array(nextPow2 - n).fill(0));
      }
      return arr;
    }

    // iFFT( Re[], Im[] ) => Normalized in place
    function ifft1D(real, imag) {
      // Conjugate
      for (let i = 0; i < real.length; i++) {
        imag[i] = -imag[i];
      }
      real = padToPowerOfTwo(real);
      imag = padToPowerOfTwo(imag);
      // Forward FFT
      [real, imag] = fft1D(real, imag);
      // Conjugate again
      for (let i = 0; i < real.length; i++) {
        real[i] = real[i] / real.length;
        imag[i] = -imag[i] / real.length;
      }
      return [real, imag];
    }

    // -------------------------------------------
    // 2D FFT using 1D transform
    // -------------------------------------------
    function fft2D(real2D, imag2D) {
      // real2D and imag2D are 2D arrays of the same size
      const rows = real2D.length;
      const cols = real2D[0].length;

      // 1) FFT each row
      for (let r = 0; r < rows; r++) {
        const rowReal = real2D[r].slice();
        const rowImag = imag2D[r].slice();
        const [rowRealOut, rowImagOut] = fft1D(rowReal, rowImag);
        real2D[r] = rowRealOut;
        imag2D[r] = rowImagOut;
      }

      // 2) FFT each column
      for (let c = 0; c < cols; c++) {
        let colReal = new Array(rows);
        let colImag = new Array(rows);
        for (let r = 0; r < rows; r++) {
          colReal[r] = real2D[r][c];
          colImag[r] = imag2D[r][c];
        }
        const [colRealOut, colImagOut] = fft1D(colReal, colImag);
        // put data back
        for (let r = 0; r < rows; r++) {
          real2D[r][c] = colRealOut[r];
          imag2D[r][c] = colImagOut[r];
        }
      }
    }

    // -------------------------------------------
    // 2D Inverse FFT
    // -------------------------------------------
    function ifft2D(real2D, imag2D) {
      const rows = real2D.length;
      const cols = real2D[0].length;

      // iFFT each row
      for (let r = 0; r < rows; r++) {
        const [rowRealOut, rowImagOut] = ifft1D(real2D[r].slice(), imag2D[r].slice());
        real2D[r] = rowRealOut;
        imag2D[r] = rowImagOut;
      }

      // iFFT each column
      for (let c = 0; c < cols; c++) {
        let colReal = new Array(rows);
        let colImag = new Array(rows);
        for (let r = 0; r < rows; r++) {
          colReal[r] = real2D[r][c];
          colImag[r] = imag2D[r][c];
        }
        const [colRealOut, colImagOut] = ifft1D(colReal, colImag);
        for (let r = 0; r < rows; r++) {
          real2D[r][c] = colRealOut[r];
          imag2D[r][c] = colImagOut[r];
        }
      }
    }

    // -------------------------------------------
    // Helper to shift the origin of the FFT
    // (so that frequency=0 is in the center)
    // -------------------------------------------
    function fftShift2D(real2D, imag2D) {
      const rows = real2D.length;
      const cols = real2D[0].length;
      const halfRows = Math.floor(rows / 2);
      const halfCols = Math.floor(cols / 2);

      // Swap quadrants: top-left <-> bottom-right, top-right <-> bottom-left
      for (let r = 0; r < halfRows; r++) {
        for (let c = 0; c < halfCols; c++) {
          // swap (r,c) with (r+halfRows, c+halfCols)
          let r2 = r + halfRows;
          let c2 = c + halfCols;
          [real2D[r][c], real2D[r2][c2]] = [real2D[r2][c2], real2D[r][c]];
          [imag2D[r][c], imag2D[r2][c2]] = [imag2D[r2][c2], imag2D[r][c]];
        }
      }
      for (let r = 0; r < halfRows; r++) {
        for (let c = halfCols; c < cols; c++) {
          // swap (r,c) with (r+halfRows, c-halfCols)
          let r2 = r + halfRows;
          let c2 = c - halfCols;
          [real2D[r][c], real2D[r2][c2]] = [real2D[r2][c2], real2D[r][c]];
          [imag2D[r][c], imag2D[r2][c2]] = [imag2D[r2][c2], imag2D[r][c]];
        }
      }
    }

    // -------------------------------------------
    // Main Demo
    // -------------------------------------------
    function initFrequencyDemo() {
      const canvasFreqIn  = document.getElementById("canvasFreqInput");
      const canvasFreqOut = document.getElementById("canvasFreqOutput");
      const cutoffSlider  = document.getElementById("cutoff");
      const imageSrc      = "image1.jpeg"; // adjust path if needed

      const freqImg = new Image();
      freqImg.src = imageSrc;

      freqImg.onload = function() {
        canvasFreqIn.width  = freqImg.width;
        canvasFreqIn.height = freqImg.height;
        canvasFreqOut.width = freqImg.width;
        canvasFreqOut.height= freqImg.height;

        // Draw image to input canvas
        const ctxIn = canvasFreqIn.getContext("2d");
        ctxIn.drawImage(freqImg, 0, 0);

        // Listen for slider changes
        cutoffSlider.addEventListener("input", applyFrequencyFilter);

        // Initial filter application
        applyFrequencyFilter();
      };

      freqImg.onerror = function() {
        console.error("Error loading image. Check the path and network.");
      };

      function applyFrequencyFilter() {
        const cutoffVal = parseInt(cutoffSlider.value);
    
        // 1) Extract grayscale from the input canvas
        const ctxIn = canvasFreqIn.getContext("2d");
        const { width, height } = canvasFreqIn;
        const imageData = ctxIn.getImageData(0, 0, width, height);
        const data = imageData.data;
    
        let real2D = new Array(height);
        let imag2D = new Array(height);
        for (let r = 0; r < height; r++) {
            real2D[r] = new Array(width).fill(0);
            imag2D[r] = new Array(width).fill(0);
        }
    
        // Convert to grayscale
        for (let i = 0, r = 0; r < height; r++) {
            for (let c = 0; c < width; c++, i += 4) {
                let gray = 0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2];
                real2D[r][c] = gray;
                imag2D[r][c] = 0;
            }
        }
    
        // 2) Perform FFT
        fft2D(real2D, imag2D);
    
        // 3) Shift frequency components
        fftShift2D(real2D, imag2D);
    
        // 4) Apply a circular low-pass filter
        const radius = (cutoffVal / 100) * (Math.min(width, height) / 2);
        const centerR = Math.floor(height / 2);
        const centerC = Math.floor(width / 2);
    
        for (let r = 0; r < height; r++) {
            for (let c = 0; c < width; c++) {
                let dist = Math.sqrt(Math.pow(r - centerR, 2) + Math.pow(c - centerC, 2));
                if (dist > radius) {
                    real2D[r][c] = 0;
                    imag2D[r][c] = 0;
                }
            }
        }
    
        // 5) Shift back before inverse FFT
        fftShift2D(real2D, imag2D);
    
        // 6) Perform inverse FFT
        ifft2D(real2D, imag2D);
    
        // -------------------------------
        // Add the normalization step here
        // -------------------------------
        const flattened = real2D.flat();
        const minVal = flattened.reduce((min, val) => Math.min(min, val), Infinity);
        const maxVal = flattened.reduce((max, val) => Math.max(max, val), -Infinity);
    
        const ctxOut = canvasFreqOut.getContext("2d");
        const outData = ctxOut.createImageData(width, height);
    
        for (let r = 0; r < height; r++) {
            for (let c = 0; c < width; c++) {
                let val = real2D[r][c];
                val = ((val - minVal) / (maxVal - minVal)) * 255;  // Normalize to [0,255]
                val = Math.round(val);
                outData.data[(r * width + c) * 4] = val;
                outData.data[(r * width + c) * 4 + 1] = val;
                outData.data[(r * width + c) * 4 + 2] = val;
                outData.data[(r * width + c) * 4 + 3] = 255;  // Full opacity
            }
        }
    
        // 7) Draw the normalized image to output canvas
        ctxOut.putImageData(outData, 0, 0);
      }
    }

    // Kick it off
    initFrequencyDemo();

    // Expose helper functions on window:
    window.toggleDemo = toggleDemo;

    console.log(`Grayscale value at (0,0): ${real2D[0][0]}`);

    </script>
</body>
</html>
